+ echo 'Beginning trial 1 of 8'
Beginning trial 1 of 8
+ echo ':::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 376 8 GPU-[790,1006,726,47,753,903,761,682] '\''unknown'\'' DGXH100_008x08x004'
:::DLPAL /mnt/localdisk1/mlperf/ssd/nvcr.io+nvdlfwea+mlperftv50+ssd+20250331.pytorch.sqsh 376 8 GPU-[790,1006,726,47,753,903,761,682] 'unknown' DGXH100_008x08x004
++ srun --ntasks=1 --container-name=single_stage_detector_376 mlperf-sysjson.sh
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
+ echo ':::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}'
:::SYSJSON {"submitter":"UNKNOWN_MLPERF_SUBMITTER","division":"closed","status":"Available on-premise","system_name":"UNKNOWN_MLPERF_SYSTEM_NAME","number_of_nodes":"8","host_processors_per_node":"2","host_processor_model_name":"Intel(R) Xeon(R) Platinum 8480+","host_processor_core_count":"56","host_processor_vcpu_count":"","host_processor_frequency":"","host_processor_caches":"","host_processor_interconnect":"","host_memory_capacity":"3.0 TB","host_storage_type":"","host_storage_capacity":"","host_networking":"","host_networking_topology":"","host_memory_configuration":"","accelerators_per_node":"8","accelerator_model_name":"NVIDIA H200","accelerator_host_interconnect":"","accelerator_frequency":"","accelerator_on-chip_memories":"","accelerator_memory_configuration":"","accelerator_memory_capacity":"143771 MiB","accelerator_interconnect":"","accelerator_interconnect_topology":"","cooling":"","hw_notes":"","framework":"PyTorch NVIDIA Release 24.09","framework_name":"","other_software_stack":{"cuda_version":"12.6.1.006","cuda_driver_version":"560.35.03","nccl_version":"2.22.3","cublas_version":"12.6.3.1002","cudnn_version":"9.4.0.58","trt_version":"10.4.0.26","dali_version":"1.41.0","mofed_version":"5.4-rdmacore39.0","openmpi_version":"4.1.7","kernel_version":"Linux 5.15.0-1074-oracle","nvidia_kernel_driver":"560.35.05"},"operating_system":"Ubuntu 22.04.4 LTS","sw_notes":""}
+ srun --ntasks=1 --container-name=single_stage_detector_376 bash -c 'echo ":::GITCOMMITID ${GIT_COMMIT_ID} ${LAUNCHER_GIT_COMMIT_ID}"'
srun: warning: can't run 1 processes on 8 nodes, setting nnodes to 1
:::GITCOMMITID  
+ srun -N1 -n1 --container-name=single_stage_detector_376 python -c ''
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on GPU-790
Clearing cache on GPU-903
Clearing cache on GPU-761
Clearing cache on GPU-1006
Clearing cache on GPU-47
Clearing cache on GPU-726
Clearing cache on GPU-682
Clearing cache on GPU-753
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=single_stage_detector_376 python -c '
from mlperf_logger import mllogger
mllogger.event(key=mllogger.constants.CACHE_CLEAR, value=True)'
:::MLLOG {"namespace": "", "time_ms": 1746033821441, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821528, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821581, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821602, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821610, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821634, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821666, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746033821760, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 3}}
+ sleep 30
+ set +e
++ date +%s
+ echo 'RUNANDTIME_START 1746033852'
RUNANDTIME_START 1746033852
+ srun --ntasks=64 --ntasks-per-node=8 --time=20 --container-name=single_stage_detector_376 --container-mounts=/mnt/localdisk5/mlperf/ssd/data/open-images-v6:/datasets/open-images-v6,/home/ubuntu/sd/ssd/log:/results,/mnt/localdisk5/mlperf/ssd/data/torch-home/hub/checkpoints:/root/.cache/torch --container-workdir=/workspace/ssd --container-env=MASTER_PORT,MASTER_ADDR slurm2pytorch ./run_and_time.sh
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 36: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 36, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 32: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 32, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 39: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 39, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 38: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 38, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 37: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 37, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 33: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 33, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
STARTING TIMING RUN AT 2025-04-30 05:24:17 PM
RANK 34: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 34, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
RANK 35: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 35, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 57: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 57, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 59: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 59, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 63: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 63, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 61: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 61, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 56: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 56, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 62: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 62, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 60: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 60, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 58: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 58, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 3: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 3, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 4: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 4, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 2: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 2, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 6: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 6, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 7: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 7, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 1: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 1, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 0: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 0, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 5: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 5, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 27: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 27, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 31: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 31, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 25: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 25, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 26: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 26, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 28: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 28, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 30: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 30, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 29: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 29, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 24: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 24, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 11: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 11, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 12: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 12, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 10: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 10, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 15: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 15, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 14: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 14, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 13: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 13, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 9: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 9, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 8: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 8, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
RANK 21: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 21, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 20: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 20, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 22: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 22, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 16: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 16, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 23: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 23, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
RANK 17: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 17, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 18: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 18, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 19: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 19, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 52: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 52, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 55: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 55, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 49: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 49, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 50: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 50, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 48: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 48, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 53: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 53, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 54: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 54, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 51: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 51, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
RANK 41: LOCAL_RANK 1, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 41, SLURM_LOCALID 1, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 47: LOCAL_RANK 7, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 47, SLURM_LOCALID 7, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 42: LOCAL_RANK 2, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 42, SLURM_LOCALID 2, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 44: LOCAL_RANK 4, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 44, SLURM_LOCALID 4, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 43: LOCAL_RANK 3, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 43, SLURM_LOCALID 3, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 46: LOCAL_RANK 6, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 46, SLURM_LOCALID 6, OMP_NUM_THREADS 1
running benchmark
RANK 45: LOCAL_RANK 5, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 45, SLURM_LOCALID 5, OMP_NUM_THREADS 1
running benchmark
STARTING TIMING RUN AT 2025-04-30 05:24:18 PM
RANK 40: LOCAL_RANK 0, MASTER_ADDR GPU-790, MASTER_PORT 29500, WORLD_SIZE 64, MLPERF_SLURM_FIRSTNODE , SLURM_JOB_ID 376, SLURM_NTASKS 64, SLURM_PROCID 40, SLURM_LOCALID 0, OMP_NUM_THREADS 1
running benchmark
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
num_gpus=8 num_sockets = 2 num_nodes=2 cores_per_socket=56
| distributed init (rank 0): env://
| distributed init (rank 43): env://
| distributed init (rank 32): env://
| distributed init (rank 44): env://
[W430 17:24:23.292002677 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.207299338 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.207308566 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 40): env://
[W430 17:24:23.210696415 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 6): env://
[W430 17:24:23.371467998 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 3): env://
[W430 17:24:23.382653655 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 53): env://
[W430 17:24:23.724558107 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 1): env://
[W430 17:24:23.419645296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 8): env://
[W430 17:24:23.836167844 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 55): env://
| distributed init (rank 48): env://
[W430 17:24:23.751403207 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.752545802 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 24): env://
| distributed init (rank 4): env://
| distributed init (rank 2): env://
| distributed init (rank 7): env://
[W430 17:24:23.452811260 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.453837487 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.453911129 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.010960875 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 50): env://
[W430 17:24:23.769722239 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 14): env://
| distributed init (rank 45): env://
| distributed init (rank 41): env://
[W430 17:24:23.871860132 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 5): env://
[W430 17:24:23.348494397 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.348511923 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.468258315 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 46): env://
| distributed init (rank 47): env://
[W430 17:24:23.350518990 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.350538565 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 34): env://
| distributed init (rank 35): env://
[W430 17:24:23.440045402 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.440073866 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 39): env://
[W430 17:24:23.442628834 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 13): env://
[W430 17:24:23.888728674 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 42): env://
[W430 17:24:23.368841248 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 9): env://
[W430 17:24:23.901536192 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 12): env://
[W430 17:24:23.910580691 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 38): env://
[W430 17:24:23.472133793 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 10): env://
| distributed init (rank 15): env://
[W430 17:24:23.914151972 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.914301533 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 37): env://
| distributed init (rank 33): env://
[W430 17:24:23.481945084 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.482690406 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 36): env://
[W430 17:24:23.488795826 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 30): env://
[W430 17:24:23.081835370 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 11): env://
[W430 17:24:23.949658711 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 49): env://
[W430 17:24:23.855441181 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 52): env://
[W430 17:24:23.857880515 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 54): env://
| distributed init (rank 51): env://
[W430 17:24:23.875202964 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.875659152 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 27): env://
[W430 17:24:23.122369509 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 25): env://
| distributed init (rank 31): env://
[W430 17:24:23.150955797 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.151001013 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 28): env://
[W430 17:24:23.175927667 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 26): env://
[W430 17:24:23.178959908 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 29): env://
[W430 17:24:23.203883296 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 17): env://
[W430 17:24:23.248119735 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 16): env://
[W430 17:24:23.308202636 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 56): env://
[W430 17:24:23.124812698 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 22): env://
[W430 17:24:23.316828670 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 61): env://
[W430 17:24:23.136097850 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 58): env://
[W430 17:24:23.145569240 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 18): env://
[W430 17:24:23.339795736 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 63): env://
[W430 17:24:23.160452726 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 59): env://
[W430 17:24:23.163534675 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 21): env://
[W430 17:24:23.354001049 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 19): env://
[W430 17:24:23.357804188 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 23): env://
[W430 17:24:23.369219271 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 20): env://
[W430 17:24:23.414265096 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 57): env://
[W430 17:24:23.248131517 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 60): env://
[W430 17:24:23.263271453 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
| distributed init (rank 62): env://
[W430 17:24:23.271085868 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
[W430 17:24:23.944570174 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())
NCCL version 2.22.3+cuda12.6
:::MLLOG {"namespace": "", "time_ms": 1746033866695, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "retinanet", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746033866696, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "SUBMISSION_ORG_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746033866696, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746033866696, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746033866696, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 352}}
:::MLLOG {"namespace": "", "time_ms": 1746033866696, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 353}}
:::MLLOG {"namespace": "", "time_ms": 1746033866728, "event_type": "POINT_IN_TIME", "key": "seed", "value": 42254337, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 368}}
:::MLLOG {"namespace": "", "time_ms": 1746033866728, "event_type": "POINT_IN_TIME", "key": "local_batch_size", "value": 4, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 371}}
:::MLLOG {"namespace": "", "time_ms": 1746033866729, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 256, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 372}}
:::MLLOG {"namespace": "", "time_ms": 1746033866729, "event_type": "POINT_IN_TIME", "key": "epoch_count", "value": 6, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 373}}
:::MLLOG {"namespace": "", "time_ms": 1746033866729, "event_type": "POINT_IN_TIME", "key": "first_epoch_num", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 374}}
Namespace(backbone='resnext50_32x4d', trainable_backbone_layers=3, sync_bn=False, data_layout='channels_last', amp=True, async_coco=True, async_coco_check_freq=20, num_eval_ranks=64, dataset='openimages-mlperf', dataset_path='/datasets/open-images-v6', num_classes=None, train_data_path=None, train_annotations_file=None, val_data_path=None, val_annotations_file=None, image_size=[800, 800], data_augmentation='hflip', epochs=6, max_iters_per_epoch=None, max_eval_iters_per_epoch=None, start_epoch=0, output_dir=None, target_map=0.34, resume='', pretrained=False, batch_size=4, eval_batch_size=32, lr=0.0001, warmup_epochs=1, warmup_factor=0.001, workers=4, print_freq=20, eval_print_freq=20, test_only=False, seed=42254337, device='cuda', cocoeval='nvidia', coco_threads=8, world_size=64, dist_url='env://', frozen_bn_opt=True, frozen_bn_fp16=True, jit=True, cuda_graphs=True, cuda_graphs_eval=False, cls_head_pad=True, reg_head_pad=True, cuda_graphs_syn=True, model_warmup_epochs=16, master_weights=True, dali=True, dali_matched_idxs=True, dali_eval=True, dali_eval_cache=False, dali_prefetch_queue_depth=2, dali_cpu_decode=False, dali_pinned_memory_size=268435456, dali_cmn=0, dali_cmn_hint=0, dali_decoder_hint_height=7360, dali_decoder_hint_width=7360, dali_decoder_hw_load=0.65, dali_input_batch_multiplier=1, dali_eval_cmn_hint=0, dali_eval_decoder_hint_height=0, dali_eval_decoder_hint_width=0, dali_eval_decoder_hw_load=0.65, dali_eval_input_batch_multiplier=1, dali_sync=False, dali_resize_first=False, apex_adam=True, apex_focal_loss=True, apex_backbone_fusion=True, apex_head_fusion=True, broadcast_buffers=False, fp16_allreduce=False, ddp_bucket_sz=25, ddp_first_bucket_sz=None, no_gradient_as_bucket_view=False, max_boxes=1000, cudnn_bench=False, deterministic=False, not_graphed_prologues=False, metric_loss=False, syn_dataset=0, sync_after_graph_replay=False, allreduce_barrier=False, skip_eval=False, cuda_profiler=False, cuda_profiler_eval=False, cuda_profiler_start=-1, cuda_profiler_stop=-1, power_benchmark=False, power_sustain_time=600, rank=0, gpu=0, distributed=True, dist_backend='nccl', ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], num_train_ranks=64, train_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], eval_ranks=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63], train_rank=0, eval_rank=0)
Getting dataset information
Creating model
:::MLLOG {"namespace": "", "time_ms": 1746033866758, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866777, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p6.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866777, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 209, "tensor": "module.backbone.fpn.extra_blocks.p7.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866780, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 211, "tensor": "module.backbone.fpn.extra_blocks.p7.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866915, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866916, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866917, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer1.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866918, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866919, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866920, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866921, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866922, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866923, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer2.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866924, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866925, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866926, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866928, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866930, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866933, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.1.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866935, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866938, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866938, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.2.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866941, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866943, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866944, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.3.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866946, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866948, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866949, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.4.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866951, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866954, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866954, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer3.5.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866956, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866961, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866963, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.conv3.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866972, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.0.downsample.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033866981, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv1.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746033866990, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv2.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746033866992, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.1.conv3.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746033867001, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv1.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
:::MLLOG {"namespace": "", "time_ms": 1746033867010, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867012, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/resnet.py", "lineno": 286, "tensor": "module.backbone.body.layer4.2.conv3.weight"}}
Downloading: "https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth" to /home/ubuntu/.cache/torch/hub/checkpoints/resnext50_32x4d-7cdf4587.pth
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 56%|    | 53.5M/95.8M [00:00<00:00, 559MB/s]100%|| 95.8M/95.8M [00:00<00:00, 380MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 63%|   | 60.2M/95.8M [00:00<00:00, 631MB/s]100%|| 95.8M/95.8M [00:00<00:00, 377MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 46%|     | 44.0M/95.8M [00:00<00:00, 460MB/s] 92%|| 88.0M/95.8M [00:00<00:00, 332MB/s]100%|| 95.8M/95.8M [00:00<00:00, 345MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 46%|     | 43.6M/95.8M [00:00<00:00, 457MB/s] 91%| | 87.2M/95.8M [00:00<00:00, 276MB/s]100%|| 95.8M/95.8M [00:00<00:00, 271MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 54%|    | 51.2M/95.8M [00:00<00:00, 537MB/s]100%|| 95.8M/95.8M [00:00<00:00, 272MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 47%|     | 45.2M/95.8M [00:00<00:00, 474MB/s] 94%|| 90.5M/95.8M [00:00<00:00, 235MB/s]100%|| 95.8M/95.8M [00:00<00:00, 259MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 43%|     | 40.9M/95.8M [00:00<00:00, 429MB/s] 85%| | 81.8M/95.8M [00:00<00:00, 241MB/s]100%|| 95.8M/95.8M [00:00<00:00, 256MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 36%|      | 34.5M/95.8M [00:00<00:00, 361MB/s] 72%|  | 69.0M/95.8M [00:00<00:00, 216MB/s]100%|| 95.8M/95.8M [00:00<00:00, 254MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867443, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867444, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867444, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867445, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867445, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.inner_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867447, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.inner_blocks.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867447, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867450, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867450, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.1.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867452, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.1.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867452, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 108, "tensor": "module.backbone.fpn.layer_blocks.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867455, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/feature_pyramid_network.py", "lineno": 110, "tensor": "module.backbone.fpn.layer_blocks.2.bias"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 45%|     | 43.1M/95.8M [00:00<00:00, 450MB/s] 90%| | 86.1M/95.8M [00:00<00:00, 279MB/s]100%|| 95.8M/95.8M [00:00<00:00, 230MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 56%|    | 53.4M/95.8M [00:00<00:00, 555MB/s]100%|| 95.8M/95.8M [00:00<00:00, 227MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867468, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.0.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867471, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867471, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867473, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867474, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867476, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867476, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 142, "tensor": "module.head.classification_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867479, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 144, "tensor": "module.head.classification_head.conv.6.bias"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 28%|       | 26.6M/95.8M [00:00<00:00, 279MB/s] 56%|    | 53.8M/95.8M [00:00<00:00, 282MB/s] 86%| | 82.5M/95.8M [00:00<00:00, 291MB/s]100%|| 95.8M/95.8M [00:00<00:00, 274MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 32%|      | 30.2M/95.8M [00:00<00:00, 316MB/s] 63%|   | 60.5M/95.8M [00:00<00:00, 260MB/s] 90%| | 85.9M/95.8M [00:00<00:00, 244MB/s]100%|| 95.8M/95.8M [00:00<00:00, 241MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 38%|      | 36.4M/95.8M [00:00<00:00, 381MB/s] 76%|  | 72.8M/95.8M [00:00<00:00, 270MB/s]100%|| 95.8M/95.8M [00:00<00:00, 213MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 45%|     | 42.8M/95.8M [00:00<00:00, 444MB/s] 89%| | 85.1M/95.8M [00:00<00:00, 203MB/s]100%|| 95.8M/95.8M [00:00<00:00, 212MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 54%|    | 51.6M/95.8M [00:00<00:00, 537MB/s]100%|| 95.8M/95.8M [00:00<00:00, 211MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867501, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 148, "tensor": "module.head.classification_head.cls_logits.weight"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 24%|       | 23.1M/95.8M [00:00<00:00, 242MB/s] 53%|    | 50.5M/95.8M [00:00<00:00, 268MB/s] 86%| | 82.4M/95.8M [00:00<00:00, 297MB/s]100%|| 95.8M/95.8M [00:00<00:00, 266MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 24.1M/95.8M [00:00<00:00, 252MB/s] 50%|     | 48.2M/95.8M [00:00<00:00, 203MB/s] 81%| | 78.0M/95.8M [00:00<00:00, 247MB/s]100%|| 95.8M/95.8M [00:00<00:00, 256MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 34%|      | 32.1M/95.8M [00:00<00:00, 336MB/s] 67%|   | 64.2M/95.8M [00:00<00:00, 228MB/s] 92%|| 87.9M/95.8M [00:00<00:00, 178MB/s]100%|| 95.8M/95.8M [00:00<00:00, 204MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 20%|        | 19.5M/95.8M [00:00<00:00, 203MB/s] 52%|    | 49.4M/95.8M [00:00<00:00, 267MB/s] 78%|  | 74.9M/95.8M [00:00<00:00, 256MB/s]100%|| 95.8M/95.8M [00:00<00:00, 246MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867525, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 150, "tensor": "module.head.classification_head.cls_logits.bias"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 35%|      | 33.9M/95.8M [00:00<00:00, 352MB/s] 70%|   | 67.5M/95.8M [00:00<00:00, 205MB/s] 94%|| 90.2M/95.8M [00:00<00:00, 191MB/s]100%|| 95.8M/95.8M [00:00<00:00, 204MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867535, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 317, "tensor": "module.head.regression_head.bbox_reg.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 319, "tensor": "module.head.regression_head.bbox_reg.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867536, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.0.weight"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 24.0M/95.8M [00:00<00:00, 251MB/s] 50%|     | 48.0M/95.8M [00:00<00:00, 194MB/s] 70%|   | 67.2M/95.8M [00:00<00:00, 189MB/s]100%|| 95.8M/95.8M [00:00<00:00, 219MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033867538, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.0.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867539, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.2.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867541, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.2.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867541, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.4.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.4.bias"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867544, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 324, "tensor": "module.head.regression_head.conv.6.weight"}}
:::MLLOG {"namespace": "", "time_ms": 1746033867546, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "/workspace/ssd/model/retinanet.py", "lineno": 326, "tensor": "module.head.regression_head.conv.6.bias"}}
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 24.1M/95.8M [00:00<00:00, 252MB/s] 58%|    | 55.9M/95.8M [00:00<00:00, 298MB/s] 88%| | 84.2M/95.8M [00:00<00:00, 259MB/s]100%|| 95.8M/95.8M [00:00<00:00, 268MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 20%|        | 19.4M/95.8M [00:00<00:00, 190MB/s] 45%|     | 43.1M/95.8M [00:00<00:00, 223MB/s] 72%|  | 68.6M/95.8M [00:00<00:00, 242MB/s] 96%|| 91.9M/95.8M [00:00<00:00, 234MB/s]100%|| 95.8M/95.8M [00:00<00:00, 235MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|       | 21.2M/95.8M [00:00<00:00, 222MB/s] 50%|     | 47.9M/95.8M [00:00<00:00, 254MB/s] 75%|  | 72.1M/95.8M [00:00<00:00, 254MB/s]100%|| 95.8M/95.8M [00:00<00:00, 236MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|       | 20.9M/95.8M [00:00<00:00, 218MB/s] 44%|     | 42.6M/95.8M [00:00<00:00, 223MB/s] 69%|   | 65.9M/95.8M [00:00<00:00, 232MB/s] 92%|| 88.1M/95.8M [00:00<00:00, 230MB/s]100%|| 95.8M/95.8M [00:00<00:00, 228MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 30%|       | 28.6M/95.8M [00:00<00:00, 300MB/s] 60%|    | 57.2M/95.8M [00:00<00:00, 197MB/s] 81%| | 78.0M/95.8M [00:00<00:00, 198MB/s]100%|| 95.8M/95.8M [00:00<00:00, 207MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|        | 17.4M/95.8M [00:00<00:00, 181MB/s] 39%|      | 37.6M/95.8M [00:00<00:00, 199MB/s] 67%|   | 64.6M/95.8M [00:00<00:00, 236MB/s] 91%| | 87.2M/95.8M [00:00<00:00, 233MB/s]100%|| 95.8M/95.8M [00:00<00:00, 231MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|       | 21.4M/95.8M [00:00<00:00, 223MB/s] 58%|    | 55.9M/95.8M [00:00<00:00, 304MB/s] 89%| | 84.9M/95.8M [00:00<00:00, 223MB/s]100%|| 95.8M/95.8M [00:00<00:00, 224MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 20%|        | 19.2M/95.8M [00:00<00:00, 201MB/s] 41%|     | 39.8M/95.8M [00:00<00:00, 209MB/s] 66%|   | 63.6M/95.8M [00:00<00:00, 227MB/s] 89%| | 85.4M/95.8M [00:00<00:00, 211MB/s]100%|| 95.8M/95.8M [00:00<00:00, 222MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 35%|      | 33.8M/95.8M [00:00<00:00, 353MB/s] 70%|   | 67.5M/95.8M [00:00<00:00, 225MB/s] 96%|| 91.5M/95.8M [00:00<00:00, 192MB/s]100%|| 95.8M/95.8M [00:00<00:00, 204MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|        | 17.9M/95.8M [00:00<00:00, 187MB/s] 49%|     | 47.0M/95.8M [00:00<00:00, 255MB/s] 75%|  | 71.4M/95.8M [00:00<00:00, 255MB/s]100%|| 95.8M/95.8M [00:00<00:00, 216MB/s]100%|| 95.8M/95.8M [00:00<00:00, 225MB/s]
Casting convolutional layers to half
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 22%|       | 21.1M/95.8M [00:00<00:00, 220MB/s] 44%|     | 42.1M/95.8M [00:00<00:00, 208MB/s] 65%|   | 62.1M/95.8M [00:00<00:00, 189MB/s] 89%| | 84.9M/95.8M [00:00<00:00, 207MB/s]100%|| 95.8M/95.8M [00:00<00:00, 214MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|        | 16.9M/95.8M [00:00<00:00, 177MB/s] 35%|      | 33.8M/95.8M [00:00<00:00, 132MB/s] 66%|   | 62.9M/95.8M [00:00<00:00, 198MB/s] 96%|| 91.9M/95.8M [00:00<00:00, 235MB/s]100%|| 95.8M/95.8M [00:00<00:00, 213MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 15%|        | 14.8M/95.8M [00:00<00:00, 154MB/s] 48%|     | 46.1M/95.8M [00:00<00:00, 256MB/s] 74%|  | 70.6M/95.8M [00:00<00:00, 218MB/s] 96%|| 92.0M/95.8M [00:00<00:00, 213MB/s]100%|| 95.8M/95.8M [00:00<00:00, 219MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 36%|      | 34.2M/95.8M [00:00<00:00, 358MB/s] 72%|  | 68.5M/95.8M [00:00<00:00, 157MB/s]100%|| 95.8M/95.8M [00:00<00:00, 196MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 23%|       | 21.8M/95.8M [00:00<00:00, 227MB/s] 45%|     | 43.4M/95.8M [00:00<00:00, 173MB/s] 65%|   | 62.1M/95.8M [00:00<00:00, 182MB/s] 92%|| 88.1M/95.8M [00:00<00:00, 214MB/s]100%|| 95.8M/95.8M [00:00<00:00, 210MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 18%|        | 17.0M/95.8M [00:00<00:00, 178MB/s] 35%|      | 34.0M/95.8M [00:00<00:00, 144MB/s] 65%|   | 62.1M/95.8M [00:00<00:00, 205MB/s] 86%| | 82.6M/95.8M [00:00<00:00, 187MB/s]100%|| 95.8M/95.8M [00:00<00:00, 194MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 20%|        | 19.5M/95.8M [00:00<00:00, 203MB/s] 41%|      | 39.0M/95.8M [00:00<00:00, 167MB/s] 71%|   | 67.6M/95.8M [00:00<00:00, 220MB/s] 93%|| 89.5M/95.8M [00:00<00:00, 212MB/s]100%|| 95.8M/95.8M [00:00<00:00, 214MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 10%|         | 10.0M/95.8M [00:00<00:00, 102MB/s] 21%|        | 19.9M/95.8M [00:00<00:00, 92.6MB/s] 37%|      | 35.2M/95.8M [00:00<00:00, 122MB/s]  58%|    | 55.9M/95.8M [00:00<00:00, 157MB/s] 77%|  | 74.0M/95.8M [00:00<00:00, 168MB/s]100%|| 95.8M/95.8M [00:00<00:00, 174MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 23%|       | 22.4M/95.8M [00:00<00:00, 234MB/s] 47%|     | 44.8M/95.8M [00:00<00:00, 164MB/s] 65%|   | 61.9M/95.8M [00:00<00:00, 169MB/s] 93%|| 89.2M/95.8M [00:00<00:00, 210MB/s]100%|| 95.8M/95.8M [00:00<00:00, 206MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 12%|        | 11.9M/95.8M [00:00<00:00, 124MB/s] 25%|       | 23.8M/95.8M [00:00<00:00, 114MB/s] 58%|    | 55.6M/95.8M [00:00<00:00, 210MB/s] 79%|  | 76.1M/95.8M [00:00<00:00, 194MB/s]100%|| 95.8M/95.8M [00:00<00:00, 204MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 32%|      | 30.6M/95.8M [00:00<00:00, 321MB/s] 64%|   | 61.2M/95.8M [00:00<00:00, 187MB/s] 93%|| 89.0M/95.8M [00:00<00:00, 221MB/s]100%|| 95.8M/95.8M [00:00<00:00, 231MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 27%|       | 25.5M/95.8M [00:00<00:00, 267MB/s] 53%|    | 51.0M/95.8M [00:00<00:00, 245MB/s] 78%|  | 74.5M/95.8M [00:00<00:00, 203MB/s]100%|| 95.8M/95.8M [00:00<00:00, 232MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|        | 17.8M/95.8M [00:00<00:00, 183MB/s] 37%|      | 35.2M/95.8M [00:00<00:00, 141MB/s] 63%|   | 59.9M/95.8M [00:00<00:00, 186MB/s] 88%| | 84.1M/95.8M [00:00<00:00, 210MB/s]100%|| 95.8M/95.8M [00:00<00:00, 203MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 19%|        | 18.6M/95.8M [00:00<00:00, 195MB/s] 39%|      | 37.2M/95.8M [00:00<00:00, 182MB/s] 62%|   | 59.6M/95.8M [00:00<00:00, 205MB/s] 83%| | 79.4M/95.8M [00:00<00:00, 185MB/s]100%|| 95.8M/95.8M [00:00<00:00, 201MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 21%|        | 19.9M/95.8M [00:00<00:00, 208MB/s] 41%|     | 39.8M/95.8M [00:00<00:00, 193MB/s] 61%|    | 58.4M/95.8M [00:00<00:00, 154MB/s] 89%| | 85.4M/95.8M [00:00<00:00, 197MB/s]100%|| 95.8M/95.8M [00:00<00:00, 202MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 21%|       | 20.4M/95.8M [00:00<00:00, 213MB/s] 43%|     | 40.8M/95.8M [00:00<00:00, 164MB/s] 60%|    | 57.1M/95.8M [00:00<00:00, 153MB/s] 89%| | 85.1M/95.8M [00:00<00:00, 200MB/s]100%|| 95.8M/95.8M [00:00<00:00, 199MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 29%|       | 27.6M/95.8M [00:00<00:00, 287MB/s] 57%|    | 55.0M/95.8M [00:00<00:00, 154MB/s] 76%|  | 72.9M/95.8M [00:00<00:00, 149MB/s]100%|| 95.8M/95.8M [00:00<00:00, 182MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 13%|        | 12.0M/95.8M [00:00<00:00, 121MB/s] 30%|       | 28.4M/95.8M [00:00<00:00, 148MB/s] 49%|     | 46.6M/95.8M [00:00<00:00, 167MB/s] 76%|  | 72.5M/95.8M [00:00<00:00, 208MB/s]100%|| 95.8M/95.8M [00:00<00:00, 223MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 23.5M/95.8M [00:00<00:00, 245MB/s] 49%|     | 46.9M/95.8M [00:00<00:00, 169MB/s] 67%|   | 64.4M/95.8M [00:00<00:00, 149MB/s] 88%| | 84.4M/95.8M [00:00<00:00, 168MB/s]100%|| 95.8M/95.8M [00:00<00:00, 181MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|        | 15.2M/95.8M [00:00<00:00, 159MB/s] 32%|      | 30.5M/95.8M [00:00<00:00, 147MB/s] 47%|     | 44.6M/95.8M [00:00<00:00, 145MB/s] 64%|   | 61.4M/95.8M [00:00<00:00, 155MB/s]100%|| 95.8M/95.8M [00:00<00:00, 197MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 23.8M/95.8M [00:00<00:00, 247MB/s] 49%|     | 47.4M/95.8M [00:00<00:00, 120MB/s] 81%|  | 77.8M/95.8M [00:00<00:00, 178MB/s]100%|| 95.8M/95.8M [00:00<00:00, 197MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|        | 13.8M/95.8M [00:00<00:00, 142MB/s] 29%|       | 27.4M/95.8M [00:00<00:00, 130MB/s] 44%|     | 42.2M/95.8M [00:00<00:00, 141MB/s] 65%|   | 62.1M/95.8M [00:00<00:00, 167MB/s] 98%|| 94.2M/95.8M [00:00<00:00, 227MB/s]100%|| 95.8M/95.8M [00:00<00:00, 192MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|        | 13.6M/95.8M [00:00<00:00, 142MB/s] 38%|      | 36.2M/95.8M [00:00<00:00, 197MB/s] 57%|    | 55.0M/95.8M [00:00<00:00, 146MB/s] 86%| | 82.8M/95.8M [00:00<00:00, 193MB/s]100%|| 95.8M/95.8M [00:00<00:00, 192MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 17%|        | 16.1M/95.8M [00:00<00:00, 165MB/s] 33%|      | 32.0M/95.8M [00:00<00:00, 125MB/s] 51%|     | 48.9M/95.8M [00:00<00:00, 145MB/s] 72%|  | 68.6M/95.8M [00:00<00:00, 167MB/s]100%|| 95.8M/95.8M [00:00<00:00, 187MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 12%|        | 11.1M/95.8M [00:00<00:00, 116MB/s] 23%|       | 22.2M/95.8M [00:00<00:00, 94.4MB/s] 41%|      | 39.1M/95.8M [00:00<00:00, 126MB/s]  63%|   | 60.0M/95.8M [00:00<00:00, 160MB/s] 97%|| 92.5M/95.8M [00:00<00:00, 222MB/s]100%|| 95.8M/95.8M [00:00<00:00, 183MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 10%|         | 9.12M/95.8M [00:00<00:00, 95.1MB/s] 21%|        | 19.8M/95.8M [00:00<00:00, 104MB/s]  44%|     | 42.5M/95.8M [00:00<00:00, 161MB/s] 72%|  | 68.5M/95.8M [00:00<00:00, 203MB/s]100%|| 95.8M/95.8M [00:00<00:00, 204MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 10%|         | 9.88M/95.8M [00:00<00:00, 102MB/s] 20%|        | 19.6M/95.8M [00:00<00:00, 83.8MB/s] 29%|       | 27.9M/95.8M [00:00<00:00, 82.3MB/s] 48%|     | 46.0M/95.8M [00:00<00:00, 121MB/s]  99%|| 95.1M/95.8M [00:00<00:00, 255MB/s]100%|| 95.8M/95.8M [00:00<00:00, 183MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s]  9%|         | 9.00M/95.8M [00:00<00:00, 94.0MB/s] 23%|       | 21.9M/95.8M [00:00<00:00, 118MB/s]  43%|     | 40.9M/95.8M [00:00<00:00, 154MB/s] 58%|    | 55.6M/95.8M [00:00<00:00, 145MB/s] 89%| | 85.5M/95.8M [00:00<00:00, 203MB/s]100%|| 95.8M/95.8M [00:00<00:00, 184MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 10%|         | 9.50M/95.8M [00:00<00:00, 99.5MB/s] 20%|        | 19.0M/95.8M [00:00<00:01, 79.5MB/s] 40%|      | 38.1M/95.8M [00:00<00:00, 128MB/s]  70%|   | 67.2M/95.8M [00:00<00:00, 192MB/s]100%|| 95.8M/95.8M [00:00<00:00, 199MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 25%|       | 23.6M/95.8M [00:00<00:00, 246MB/s] 49%|     | 47.2M/95.8M [00:00<00:00, 120MB/s] 75%|  | 71.9M/95.8M [00:00<00:00, 160MB/s]100%|| 95.8M/95.8M [00:00<00:00, 174MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 16%|        | 15.0M/95.8M [00:00<00:00, 154MB/s] 31%|       | 29.8M/95.8M [00:00<00:00, 100MB/s] 49%|     | 47.2M/95.8M [00:00<00:00, 129MB/s] 88%| | 84.4M/95.8M [00:00<00:00, 216MB/s]100%|| 95.8M/95.8M [00:00<00:00, 191MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 14%|        | 13.4M/95.8M [00:00<00:00, 139MB/s] 28%|       | 26.8M/95.8M [00:00<00:00, 133MB/s] 41%|      | 39.5M/95.8M [00:00<00:00, 115MB/s] 54%|    | 51.2M/95.8M [00:00<00:00, 118MB/s] 81%|  | 77.5M/95.8M [00:00<00:00, 170MB/s]100%|| 95.8M/95.8M [00:00<00:00, 160MB/s]
  0%|          | 0.00/95.8M [00:00<?, ?B/s] 21%|        | 19.9M/95.8M [00:00<00:00, 208MB/s] 43%|     | 40.8M/95.8M [00:00<00:00, 213MB/s] 64%|   | 61.1M/95.8M [00:00<00:00, 181MB/s] 82%| | 78.9M/95.8M [00:00<00:00, 152MB/s] 98%|| 94.1M/95.8M [00:00<00:00, 145MB/s]100%|| 95.8M/95.8M [00:00<00:00, 161MB/s]
:::MLLOG {"namespace": "", "time_ms": 1746033868072, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "adam", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 450}}
:::MLLOG {"namespace": "", "time_ms": 1746033868072, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 451}}
:::MLLOG {"namespace": "", "time_ms": 1746033868072, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 452}}
:::MLLOG {"namespace": "", "time_ms": 1746033868073, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 453}}
:::MLLOG {"namespace": "", "time_ms": 1746033868073, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.001, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 454}}
:::MLLOG {"namespace": "", "time_ms": 1746033868073, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 455}}
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Model eval warmup
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Time: 53.718010902404785 sec
Creating Dali training dataloader
Creating Dali eval dataloader
CUDA graph capture for training
CUDA graphs: data preprocessing complete
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py:415: FutureWarning: GradScaler is going to stop passing itself as a keyword argument to the passed optimizer. In the near future GradScaler registers `grad_scale: Tensor` and `found_inf: Tensor` to the passed optimizer and let the optimizer use them directly.
  warnings.warn(
CUDA graphs: warmup iterations complete
CUDA graphs: capture complete
CUDA graph capture for training complete
:::MLLOG {"namespace": "", "time_ms": 1746033946883, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 575}}
:::MLLOG {"namespace": "", "time_ms": 1746033946884, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 579}}
:::MLLOG {"namespace": "", "time_ms": 1746033946884, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 4572, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 633}}
:::MLLOG {"namespace": "", "time_ms": 1746033946884, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 13, "metadata": {"file": "/workspace/ssd/train.py", "lineno": 636}}
Running ...
:::MLLOG {"namespace": "", "time_ms": 1746033946885, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 0}}
Epoch: [0]  [   0/4572]  eta: 0:01:20    time: 0.0177  data: 0.0002  max mem: 13749
Epoch: [0]  [  20/4572]  eta: 0:01:37    time: 0.0216  data: 0.0200  max mem: 13749
Epoch: [0]  [  40/4572]  eta: 0:01:38    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [  60/4572]  eta: 0:01:38    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [  80/4572]  eta: 0:01:41    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [0]  [ 100/4572]  eta: 0:01:42    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [0]  [ 120/4572]  eta: 0:01:41    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [0]  [ 140/4572]  eta: 0:01:42    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [0]  [ 160/4572]  eta: 0:01:41    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0]  [ 180/4572]  eta: 0:01:41    time: 0.0233  data: 0.0209  max mem: 13749
Epoch: [0]  [ 200/4572]  eta: 0:01:40    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [ 220/4572]  eta: 0:01:39    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [ 240/4572]  eta: 0:01:39    time: 0.0222  data: 0.0205  max mem: 13749
Epoch: [0]  [ 260/4572]  eta: 0:01:38    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [ 280/4572]  eta: 0:01:38    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [0]  [ 300/4572]  eta: 0:01:37    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 320/4572]  eta: 0:01:37    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [0]  [ 340/4572]  eta: 0:01:36    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [ 360/4572]  eta: 0:01:36    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [ 380/4572]  eta: 0:01:36    time: 0.0251  data: 0.0225  max mem: 13749
Epoch: [0]  [ 400/4572]  eta: 0:01:36    time: 0.0253  data: 0.0228  max mem: 13749
Epoch: [0]  [ 420/4572]  eta: 0:01:35    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 440/4572]  eta: 0:01:35    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 460/4572]  eta: 0:01:34    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [ 480/4572]  eta: 0:01:34    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [0]  [ 500/4572]  eta: 0:01:33    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 520/4572]  eta: 0:01:33    time: 0.0246  data: 0.0230  max mem: 13749
Epoch: [0]  [ 540/4572]  eta: 0:01:33    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [0]  [ 560/4572]  eta: 0:01:32    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [0]  [ 580/4572]  eta: 0:01:32    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [0]  [ 600/4572]  eta: 0:01:31    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 620/4572]  eta: 0:01:31    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [ 640/4572]  eta: 0:01:30    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [ 660/4572]  eta: 0:01:30    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [ 680/4572]  eta: 0:01:29    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [ 700/4572]  eta: 0:01:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [ 720/4572]  eta: 0:01:28    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0]  [ 740/4572]  eta: 0:01:28    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [ 760/4572]  eta: 0:01:27    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [0]  [ 780/4572]  eta: 0:01:27    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [0]  [ 800/4572]  eta: 0:01:27    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [0]  [ 820/4572]  eta: 0:01:26    time: 0.0230  data: 0.0211  max mem: 13749
Epoch: [0]  [ 840/4572]  eta: 0:01:26    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [ 860/4572]  eta: 0:01:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [ 880/4572]  eta: 0:01:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [ 900/4572]  eta: 0:01:24    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [ 920/4572]  eta: 0:01:24    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [ 940/4572]  eta: 0:01:23    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [ 960/4572]  eta: 0:01:23    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [ 980/4572]  eta: 0:01:22    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1000/4572]  eta: 0:01:22    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [1020/4572]  eta: 0:01:21    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [1040/4572]  eta: 0:01:21    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [1060/4572]  eta: 0:01:20    time: 0.0255  data: 0.0240  max mem: 13749
Epoch: [0]  [1080/4572]  eta: 0:01:20    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [1100/4572]  eta: 0:01:20    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [1120/4572]  eta: 0:01:19    time: 0.0236  data: 0.0219  max mem: 13749
Epoch: [0]  [1140/4572]  eta: 0:01:19    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1160/4572]  eta: 0:01:18    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1180/4572]  eta: 0:01:18    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1200/4572]  eta: 0:01:17    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [0]  [1220/4572]  eta: 0:01:17    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [1240/4572]  eta: 0:01:16    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [1260/4572]  eta: 0:01:16    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [1280/4572]  eta: 0:01:15    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [1300/4572]  eta: 0:01:15    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [1320/4572]  eta: 0:01:14    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [1340/4572]  eta: 0:01:14    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [1360/4572]  eta: 0:01:13    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1380/4572]  eta: 0:01:13    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [1400/4572]  eta: 0:01:12    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1420/4572]  eta: 0:01:12    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [0]  [1440/4572]  eta: 0:01:12    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [1460/4572]  eta: 0:01:11    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [1480/4572]  eta: 0:01:11    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [1500/4572]  eta: 0:01:10    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [0]  [1520/4572]  eta: 0:01:10    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1540/4572]  eta: 0:01:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [1560/4572]  eta: 0:01:09    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [1580/4572]  eta: 0:01:08    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [1600/4572]  eta: 0:01:08    time: 0.0239  data: 0.0220  max mem: 13749
Epoch: [0]  [1620/4572]  eta: 0:01:07    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1640/4572]  eta: 0:01:07    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [1660/4572]  eta: 0:01:07    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [0]  [1680/4572]  eta: 0:01:06    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [1700/4572]  eta: 0:01:06    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [1740/4572]  eta: 0:01:05    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [0]  [1760/4572]  eta: 0:01:04    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [1780/4572]  eta: 0:01:04    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1800/4572]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [1820/4572]  eta: 0:01:03    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [1840/4572]  eta: 0:01:02    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [1860/4572]  eta: 0:01:02    time: 0.0230  data: 0.0213  max mem: 13749
Epoch: [0]  [1880/4572]  eta: 0:01:01    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [0]  [1900/4572]  eta: 0:01:01    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [1920/4572]  eta: 0:01:01    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [1940/4572]  eta: 0:01:00    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [1960/4572]  eta: 0:01:00    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [0]  [1980/4572]  eta: 0:00:59    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2000/4572]  eta: 0:00:59    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [0]  [2020/4572]  eta: 0:00:58    time: 0.0222  data: 0.0203  max mem: 13749
Epoch: [0]  [2040/4572]  eta: 0:00:58    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [2060/4572]  eta: 0:00:57    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2080/4572]  eta: 0:00:57    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2100/4572]  eta: 0:00:56    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [0]  [2120/4572]  eta: 0:00:56    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [2140/4572]  eta: 0:00:55    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [0]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2180/4572]  eta: 0:00:55    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [2200/4572]  eta: 0:00:54    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2220/4572]  eta: 0:00:54    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2240/4572]  eta: 0:00:53    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [2260/4572]  eta: 0:00:53    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2280/4572]  eta: 0:00:52    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [0]  [2300/4572]  eta: 0:00:52    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [0]  [2320/4572]  eta: 0:00:51    time: 0.0221  data: 0.0207  max mem: 13749
Epoch: [0]  [2340/4572]  eta: 0:00:51    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [0]  [2360/4572]  eta: 0:00:50    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [0]  [2380/4572]  eta: 0:00:50    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [2400/4572]  eta: 0:00:50    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [2420/4572]  eta: 0:00:49    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [2440/4572]  eta: 0:00:49    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [2460/4572]  eta: 0:00:48    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [2480/4572]  eta: 0:00:48    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2500/4572]  eta: 0:00:47    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [2520/4572]  eta: 0:00:47    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [2540/4572]  eta: 0:00:46    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [0]  [2560/4572]  eta: 0:00:46    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2580/4572]  eta: 0:00:45    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [2600/4572]  eta: 0:00:45    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [0]  [2620/4572]  eta: 0:00:44    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [2640/4572]  eta: 0:00:44    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [0]  [2660/4572]  eta: 0:00:44    time: 0.0254  data: 0.0239  max mem: 13749
Epoch: [0]  [2680/4572]  eta: 0:00:43    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [2700/4572]  eta: 0:00:43    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [2720/4572]  eta: 0:00:42    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [0]  [2740/4572]  eta: 0:00:42    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [2760/4572]  eta: 0:00:41    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [2780/4572]  eta: 0:00:41    time: 0.0223  data: 0.0206  max mem: 13749
Epoch: [0]  [2800/4572]  eta: 0:00:40    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [0]  [2820/4572]  eta: 0:00:40    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [2840/4572]  eta: 0:00:39    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0]  [2860/4572]  eta: 0:00:39    time: 0.0233  data: 0.0216  max mem: 13749
Epoch: [0]  [2880/4572]  eta: 0:00:38    time: 0.0220  data: 0.0206  max mem: 13749
Epoch: [0]  [2900/4572]  eta: 0:00:38    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [0]  [2920/4572]  eta: 0:00:38    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [0]  [2940/4572]  eta: 0:00:37    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [0]  [2960/4572]  eta: 0:00:37    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [2980/4572]  eta: 0:00:36    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [3000/4572]  eta: 0:00:36    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3020/4572]  eta: 0:00:35    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3040/4572]  eta: 0:00:35    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [0]  [3060/4572]  eta: 0:00:34    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3080/4572]  eta: 0:00:34    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [0]  [3100/4572]  eta: 0:00:33    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3120/4572]  eta: 0:00:33    time: 0.0228  data: 0.0210  max mem: 13749
Epoch: [0]  [3140/4572]  eta: 0:00:32    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3160/4572]  eta: 0:00:32    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [0]  [3180/4572]  eta: 0:00:32    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [0]  [3200/4572]  eta: 0:00:31    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [3220/4572]  eta: 0:00:31    time: 0.0237  data: 0.0223  max mem: 13749
Epoch: [0]  [3240/4572]  eta: 0:00:30    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3260/4572]  eta: 0:00:30    time: 0.0238  data: 0.0216  max mem: 13749
Epoch: [0]  [3280/4572]  eta: 0:00:29    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [0]  [3300/4572]  eta: 0:00:29    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [0]  [3320/4572]  eta: 0:00:28    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [0]  [3340/4572]  eta: 0:00:28    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3360/4572]  eta: 0:00:27    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3380/4572]  eta: 0:00:27    time: 0.0236  data: 0.0217  max mem: 13749
Epoch: [0]  [3400/4572]  eta: 0:00:26    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [3420/4572]  eta: 0:00:26    time: 0.0231  data: 0.0211  max mem: 13749
Epoch: [0]  [3440/4572]  eta: 0:00:26    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [0]  [3460/4572]  eta: 0:00:25    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [0]  [3480/4572]  eta: 0:00:25    time: 0.0236  data: 0.0214  max mem: 13749
Epoch: [0]  [3500/4572]  eta: 0:00:24    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3520/4572]  eta: 0:00:24    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [3540/4572]  eta: 0:00:23    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [3560/4572]  eta: 0:00:23    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3580/4572]  eta: 0:00:22    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [3600/4572]  eta: 0:00:22    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3620/4572]  eta: 0:00:21    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3640/4572]  eta: 0:00:21    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3660/4572]  eta: 0:00:20    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [0]  [3680/4572]  eta: 0:00:20    time: 0.0244  data: 0.0218  max mem: 13749
Epoch: [0]  [3700/4572]  eta: 0:00:20    time: 0.0243  data: 0.0218  max mem: 13749
Epoch: [0]  [3720/4572]  eta: 0:00:19    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [0]  [3740/4572]  eta: 0:00:19    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [3760/4572]  eta: 0:00:18    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3780/4572]  eta: 0:00:18    time: 0.0219  data: 0.0205  max mem: 13749
Epoch: [0]  [3800/4572]  eta: 0:00:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [3820/4572]  eta: 0:00:17    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [3840/4572]  eta: 0:00:16    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [3860/4572]  eta: 0:00:16    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3880/4572]  eta: 0:00:15    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [3900/4572]  eta: 0:00:15    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [0]  [3920/4572]  eta: 0:00:14    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [3940/4572]  eta: 0:00:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [3960/4572]  eta: 0:00:14    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [3980/4572]  eta: 0:00:13    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [0]  [4000/4572]  eta: 0:00:13    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [0]  [4020/4572]  eta: 0:00:12    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [0]  [4040/4572]  eta: 0:00:12    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [0]  [4060/4572]  eta: 0:00:11    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [0]  [4080/4572]  eta: 0:00:11    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [0]  [4100/4572]  eta: 0:00:10    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [0]  [4120/4572]  eta: 0:00:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [4140/4572]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4160/4572]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4180/4572]  eta: 0:00:09    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [0]  [4200/4572]  eta: 0:00:08    time: 0.0250  data: 0.0236  max mem: 13749
Epoch: [0]  [4220/4572]  eta: 0:00:08    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [4240/4572]  eta: 0:00:07    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [0]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [0]  [4280/4572]  eta: 0:00:06    time: 0.0238  data: 0.0218  max mem: 13749
Epoch: [0]  [4300/4572]  eta: 0:00:06    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [0]  [4320/4572]  eta: 0:00:05    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [0]  [4340/4572]  eta: 0:00:05    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [0]  [4360/4572]  eta: 0:00:04    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [0]  [4380/4572]  eta: 0:00:04    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [0]  [4400/4572]  eta: 0:00:03    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [0]  [4420/4572]  eta: 0:00:03    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [0]  [4440/4572]  eta: 0:00:03    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [0]  [4460/4572]  eta: 0:00:02    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [0]  [4480/4572]  eta: 0:00:02    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [0]  [4500/4572]  eta: 0:00:01    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [0]  [4520/4572]  eta: 0:00:01    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [0]  [4540/4572]  eta: 0:00:00    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [0]  [4560/4572]  eta: 0:00:00    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [0]  [4571/4572]  eta: 0:00:00    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [0] Total time: 0:01:45 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746034052011, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 0, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 0}}
:::MLLOG {"namespace": "", "time_ms": 1746034052011, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.0129293249755}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746034052014, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 1}}
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [ 0/13]  eta: 0:00:07  model_time: 0.5318 (0.5318)  evaluator_time: 0.0054 (0.0054)  time: 0.5406  data: 0.0005  max mem: 13749
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
/workspace/ssd/model/transform.py:211: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  torch.tensor(s, dtype=torch.float32, device=boxes.device) /
Test:  [12/13]  eta: 0:00:00  model_time: 0.3619 (0.3460)  evaluator_time: 0.0054 (0.0049)  time: 0.3521  data: 0.0008  max mem: 13749
Test: Total time: 0:00:04 (0.3522 s / it)
Averaged stats: model_time: 0.3619 (0.3580)  evaluator_time: 0.0054 (0.0050)
:::MLLOG {"namespace": "", "time_ms": 1746034057496, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 1}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [1]  [   0/4571]  eta: 0:01:37    time: 0.0214  data: 0.0008  max mem: 13749
Epoch: [1]  [  20/4571]  eta: 0:01:41    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [  40/4571]  eta: 0:01:45    time: 0.0245  data: 0.0229  max mem: 13749
Epoch: [1]  [  60/4571]  eta: 0:01:43    time: 0.0219  data: 0.0203  max mem: 13749
Epoch: [1]  [  80/4571]  eta: 0:01:41    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 100/4571]  eta: 0:01:42    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 120/4571]  eta: 0:01:42    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [1]  [ 140/4571]  eta: 0:01:43    time: 0.0252  data: 0.0224  max mem: 13749
Epoch: [1]  [ 160/4571]  eta: 0:01:43    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [1]  [ 180/4571]  eta: 0:01:43    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [ 200/4571]  eta: 0:01:42    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 220/4571]  eta: 0:01:41    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [1]  [ 240/4571]  eta: 0:01:41    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [ 260/4571]  eta: 0:01:40    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [ 280/4571]  eta: 0:01:40    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [1]  [ 300/4571]  eta: 0:01:39    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [ 320/4571]  eta: 0:01:38    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 340/4571]  eta: 0:01:38    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [1]  [ 360/4571]  eta: 0:01:37    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [ 380/4571]  eta: 0:01:37    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [1]  [ 400/4571]  eta: 0:01:36    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [1]  [ 420/4571]  eta: 0:01:36    time: 0.0219  data: 0.0202  max mem: 13749
Epoch: [1]  [ 440/4571]  eta: 0:01:35    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [ 460/4571]  eta: 0:01:34    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [ 480/4571]  eta: 0:01:34    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 500/4571]  eta: 0:01:33    time: 0.0224  data: 0.0205  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746034069405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.19630564384681648, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746034069405, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 1}}
Epoch: [1]  [ 520/4571]  eta: 0:01:33    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [ 540/4571]  eta: 0:01:33    time: 0.0239  data: 0.0219  max mem: 13749
Epoch: [1]  [ 560/4571]  eta: 0:01:32    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [ 580/4571]  eta: 0:01:32    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [ 600/4571]  eta: 0:01:31    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [ 620/4571]  eta: 0:01:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [ 640/4571]  eta: 0:01:30    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 660/4571]  eta: 0:01:30    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [ 680/4571]  eta: 0:01:29    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [ 700/4571]  eta: 0:01:29    time: 0.0230  data: 0.0210  max mem: 13749
Epoch: [1]  [ 720/4571]  eta: 0:01:28    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [ 740/4571]  eta: 0:01:28    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [ 760/4571]  eta: 0:01:27    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 780/4571]  eta: 0:01:27    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [ 800/4571]  eta: 0:01:26    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [ 820/4571]  eta: 0:01:26    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [ 840/4571]  eta: 0:01:25    time: 0.0247  data: 0.0228  max mem: 13749
Epoch: [1]  [ 860/4571]  eta: 0:01:25    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [ 880/4571]  eta: 0:01:24    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [1]  [ 900/4571]  eta: 0:01:24    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [ 920/4571]  eta: 0:01:23    time: 0.0227  data: 0.0206  max mem: 13749
Epoch: [1]  [ 940/4571]  eta: 0:01:23    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [ 960/4571]  eta: 0:01:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [ 980/4571]  eta: 0:01:22    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [1]  [1000/4571]  eta: 0:01:22    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1020/4571]  eta: 0:01:21    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [1040/4571]  eta: 0:01:21    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1060/4571]  eta: 0:01:20    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [1080/4571]  eta: 0:01:20    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1100/4571]  eta: 0:01:19    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1120/4571]  eta: 0:01:19    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [1]  [1140/4571]  eta: 0:01:18    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1160/4571]  eta: 0:01:18    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1180/4571]  eta: 0:01:17    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [1200/4571]  eta: 0:01:17    time: 0.0234  data: 0.0211  max mem: 13749
Epoch: [1]  [1220/4571]  eta: 0:01:16    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1240/4571]  eta: 0:01:16    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [1260/4571]  eta: 0:01:16    time: 0.0242  data: 0.0218  max mem: 13749
Epoch: [1]  [1280/4571]  eta: 0:01:15    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1300/4571]  eta: 0:01:15    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1320/4571]  eta: 0:01:14    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [1340/4571]  eta: 0:01:14    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1360/4571]  eta: 0:01:13    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1380/4571]  eta: 0:01:13    time: 0.0229  data: 0.0210  max mem: 13749
Epoch: [1]  [1400/4571]  eta: 0:01:12    time: 0.0228  data: 0.0208  max mem: 13749
Epoch: [1]  [1420/4571]  eta: 0:01:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1440/4571]  eta: 0:01:11    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [1460/4571]  eta: 0:01:11    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [1]  [1480/4571]  eta: 0:01:11    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [1500/4571]  eta: 0:01:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [1520/4571]  eta: 0:01:10    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [1540/4571]  eta: 0:01:09    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [1560/4571]  eta: 0:01:09    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [1580/4571]  eta: 0:01:08    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1600/4571]  eta: 0:01:08    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [1620/4571]  eta: 0:01:07    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [1]  [1640/4571]  eta: 0:01:07    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [1]  [1660/4571]  eta: 0:01:06    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [1]  [1680/4571]  eta: 0:01:06    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [1700/4571]  eta: 0:01:05    time: 0.0237  data: 0.0219  max mem: 13749
Epoch: [1]  [1720/4571]  eta: 0:01:05    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [1]  [1740/4571]  eta: 0:01:04    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [1760/4571]  eta: 0:01:04    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [1]  [1780/4571]  eta: 0:01:04    time: 0.0223  data: 0.0198  max mem: 13749
Epoch: [1]  [1800/4571]  eta: 0:01:03    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [1820/4571]  eta: 0:01:03    time: 0.0237  data: 0.0217  max mem: 13749
Epoch: [1]  [1840/4571]  eta: 0:01:02    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [1860/4571]  eta: 0:01:02    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [1880/4571]  eta: 0:01:01    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [1900/4571]  eta: 0:01:01    time: 0.0252  data: 0.0231  max mem: 13749
Epoch: [1]  [1920/4571]  eta: 0:01:00    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [1940/4571]  eta: 0:01:00    time: 0.0239  data: 0.0225  max mem: 13749
Epoch: [1]  [1960/4571]  eta: 0:00:59    time: 0.0231  data: 0.0213  max mem: 13749
Epoch: [1]  [1980/4571]  eta: 0:00:59    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2000/4571]  eta: 0:00:58    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2020/4571]  eta: 0:00:58    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [1]  [2040/4571]  eta: 0:00:58    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [2060/4571]  eta: 0:00:57    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [2080/4571]  eta: 0:00:57    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2100/4571]  eta: 0:00:56    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [2120/4571]  eta: 0:00:56    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2140/4571]  eta: 0:00:55    time: 0.0228  data: 0.0195  max mem: 13749
Epoch: [1]  [2160/4571]  eta: 0:00:55    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2180/4571]  eta: 0:00:54    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [2200/4571]  eta: 0:00:54    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [2220/4571]  eta: 0:00:53    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [2240/4571]  eta: 0:00:53    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [2260/4571]  eta: 0:00:52    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [2280/4571]  eta: 0:00:52    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [1]  [2300/4571]  eta: 0:00:52    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2320/4571]  eta: 0:00:51    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [2340/4571]  eta: 0:00:51    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [1]  [2360/4571]  eta: 0:00:50    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [1]  [2380/4571]  eta: 0:00:50    time: 0.0233  data: 0.0213  max mem: 13749
Epoch: [1]  [2400/4571]  eta: 0:00:49    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2420/4571]  eta: 0:00:49    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2440/4571]  eta: 0:00:48    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [2460/4571]  eta: 0:00:48    time: 0.0228  data: 0.0199  max mem: 13749
Epoch: [1]  [2480/4571]  eta: 0:00:47    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [1]  [2500/4571]  eta: 0:00:47    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [2520/4571]  eta: 0:00:47    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [2540/4571]  eta: 0:00:46    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2560/4571]  eta: 0:00:46    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2580/4571]  eta: 0:00:45    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [2600/4571]  eta: 0:00:45    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [2620/4571]  eta: 0:00:44    time: 0.0224  data: 0.0205  max mem: 13749
Epoch: [1]  [2640/4571]  eta: 0:00:44    time: 0.0240  data: 0.0223  max mem: 13749
Epoch: [1]  [2660/4571]  eta: 0:00:43    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [2680/4571]  eta: 0:00:43    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [2700/4571]  eta: 0:00:42    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2720/4571]  eta: 0:00:42    time: 0.0221  data: 0.0201  max mem: 13749
Epoch: [1]  [2740/4571]  eta: 0:00:41    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [1]  [2760/4571]  eta: 0:00:41    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [2780/4571]  eta: 0:00:41    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [2800/4571]  eta: 0:00:40    time: 0.0225  data: 0.0208  max mem: 13749
Epoch: [1]  [2820/4571]  eta: 0:00:40    time: 0.0255  data: 0.0240  max mem: 13749
Epoch: [1]  [2840/4571]  eta: 0:00:39    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2860/4571]  eta: 0:00:39    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [1]  [2880/4571]  eta: 0:00:38    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [2920/4571]  eta: 0:00:37    time: 0.0224  data: 0.0204  max mem: 13749
Epoch: [1]  [2940/4571]  eta: 0:00:37    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [2960/4571]  eta: 0:00:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [2980/4571]  eta: 0:00:36    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3000/4571]  eta: 0:00:36    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [1]  [3020/4571]  eta: 0:00:35    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3040/4571]  eta: 0:00:35    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [1]  [3060/4571]  eta: 0:00:34    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [3080/4571]  eta: 0:00:34    time: 0.0220  data: 0.0194  max mem: 13749
Epoch: [1]  [3100/4571]  eta: 0:00:33    time: 0.0231  data: 0.0213  max mem: 13749
Epoch: [1]  [3120/4571]  eta: 0:00:33    time: 0.0247  data: 0.0233  max mem: 13749
Epoch: [1]  [3140/4571]  eta: 0:00:32    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [1]  [3160/4571]  eta: 0:00:32    time: 0.0252  data: 0.0237  max mem: 13749
Epoch: [1]  [3180/4571]  eta: 0:00:31    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [1]  [3200/4571]  eta: 0:00:31    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3220/4571]  eta: 0:00:31    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [1]  [3240/4571]  eta: 0:00:30    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3260/4571]  eta: 0:00:30    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3280/4571]  eta: 0:00:29    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3300/4571]  eta: 0:00:29    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3320/4571]  eta: 0:00:28    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3340/4571]  eta: 0:00:28    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [3360/4571]  eta: 0:00:27    time: 0.0241  data: 0.0225  max mem: 13749
Epoch: [1]  [3380/4571]  eta: 0:00:27    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3400/4571]  eta: 0:00:26    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3420/4571]  eta: 0:00:26    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [1]  [3440/4571]  eta: 0:00:25    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3460/4571]  eta: 0:00:25    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3480/4571]  eta: 0:00:25    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [1]  [3500/4571]  eta: 0:00:24    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [3520/4571]  eta: 0:00:24    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [1]  [3540/4571]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [1]  [3560/4571]  eta: 0:00:23    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [1]  [3580/4571]  eta: 0:00:22    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [1]  [3600/4571]  eta: 0:00:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3620/4571]  eta: 0:00:21    time: 0.0229  data: 0.0215  max mem: 13749
Epoch: [1]  [3640/4571]  eta: 0:00:21    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [1]  [3660/4571]  eta: 0:00:20    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [1]  [3680/4571]  eta: 0:00:20    time: 0.0228  data: 0.0204  max mem: 13749
Epoch: [1]  [3700/4571]  eta: 0:00:19    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [3720/4571]  eta: 0:00:19    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [1]  [3740/4571]  eta: 0:00:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3760/4571]  eta: 0:00:18    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [3780/4571]  eta: 0:00:18    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [1]  [3800/4571]  eta: 0:00:17    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3820/4571]  eta: 0:00:17    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [3840/4571]  eta: 0:00:16    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [3860/4571]  eta: 0:00:16    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [1]  [3880/4571]  eta: 0:00:15    time: 0.0236  data: 0.0222  max mem: 13749
Epoch: [1]  [3900/4571]  eta: 0:00:15    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [3920/4571]  eta: 0:00:14    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [1]  [3940/4571]  eta: 0:00:14    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [3960/4571]  eta: 0:00:14    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [1]  [3980/4571]  eta: 0:00:13    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [1]  [4000/4571]  eta: 0:00:13    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [4020/4571]  eta: 0:00:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [4040/4571]  eta: 0:00:12    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [4060/4571]  eta: 0:00:11    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [4080/4571]  eta: 0:00:11    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [1]  [4100/4571]  eta: 0:00:10    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [1]  [4120/4571]  eta: 0:00:10    time: 0.0226  data: 0.0204  max mem: 13749
Epoch: [1]  [4140/4571]  eta: 0:00:09    time: 0.0241  data: 0.0215  max mem: 13749
Epoch: [1]  [4160/4571]  eta: 0:00:09    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4180/4571]  eta: 0:00:08    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [4200/4571]  eta: 0:00:08    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [1]  [4220/4571]  eta: 0:00:08    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [1]  [4240/4571]  eta: 0:00:07    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [4260/4571]  eta: 0:00:07    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [1]  [4280/4571]  eta: 0:00:06    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [1]  [4300/4571]  eta: 0:00:06    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [4320/4571]  eta: 0:00:05    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [1]  [4340/4571]  eta: 0:00:05    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [1]  [4360/4571]  eta: 0:00:04    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [1]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [1]  [4400/4571]  eta: 0:00:03    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [4420/4571]  eta: 0:00:03    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [1]  [4440/4571]  eta: 0:00:03    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [1]  [4460/4571]  eta: 0:00:02    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [1]  [4480/4571]  eta: 0:00:02    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [1]  [4500/4571]  eta: 0:00:01    time: 0.0217  data: 0.0203  max mem: 13749
Epoch: [1]  [4520/4571]  eta: 0:00:01    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [1]  [4540/4571]  eta: 0:00:00    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [1]  [4560/4571]  eta: 0:00:00    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [1]  [4570/4571]  eta: 0:00:00    time: 0.0247  data: 0.0232  max mem: 13749
Epoch: [1] Total time: 0:01:44 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746034162476, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 1, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1746034162476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.21514565910496}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746034162479, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 2}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2835 (0.2835)  evaluator_time: 0.0034 (0.0034)  time: 0.2879  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2767 (0.2659)  evaluator_time: 0.0036 (0.0035)  time: 0.2704  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2704 s / it)
Averaged stats: model_time: 0.2767 (0.2753)  evaluator_time: 0.0036 (0.0035)
:::MLLOG {"namespace": "", "time_ms": 1746034166580, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 2}}
Epoch: [2]  [   0/4572]  eta: 0:01:35    time: 0.0208  data: 0.0007  max mem: 13749
Epoch: [2]  [  20/4572]  eta: 0:01:42    time: 0.0226  data: 0.0209  max mem: 13749
Epoch: [2]  [  40/4572]  eta: 0:01:40    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [  60/4572]  eta: 0:01:40    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [  80/4572]  eta: 0:01:40    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [ 100/4572]  eta: 0:01:40    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [ 120/4572]  eta: 0:01:40    time: 0.0229  data: 0.0211  max mem: 13749
Epoch: [2]  [ 140/4572]  eta: 0:01:39    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [ 160/4572]  eta: 0:01:38    time: 0.0221  data: 0.0194  max mem: 13749
Epoch: [2]  [ 180/4572]  eta: 0:01:38    time: 0.0218  data: 0.0201  max mem: 13749
Epoch: [2]  [ 200/4572]  eta: 0:01:37    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [ 220/4572]  eta: 0:01:37    time: 0.0223  data: 0.0206  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746034171889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.2912799311668488, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746034171889, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 2}}
Epoch: [2]  [ 240/4572]  eta: 0:01:36    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [2]  [ 260/4572]  eta: 0:01:36    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [ 280/4572]  eta: 0:01:36    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [ 300/4572]  eta: 0:01:36    time: 0.0229  data: 0.0211  max mem: 13749
Epoch: [2]  [ 320/4572]  eta: 0:01:35    time: 0.0229  data: 0.0212  max mem: 13749
Epoch: [2]  [ 340/4572]  eta: 0:01:35    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [ 360/4572]  eta: 0:01:34    time: 0.0226  data: 0.0210  max mem: 13749
Epoch: [2]  [ 380/4572]  eta: 0:01:34    time: 0.0225  data: 0.0207  max mem: 13749
Epoch: [2]  [ 400/4572]  eta: 0:01:34    time: 0.0236  data: 0.0217  max mem: 13749
Epoch: [2]  [ 420/4572]  eta: 0:01:33    time: 0.0217  data: 0.0201  max mem: 13749
Epoch: [2]  [ 440/4572]  eta: 0:01:33    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [ 460/4572]  eta: 0:01:33    time: 0.0240  data: 0.0220  max mem: 13749
Epoch: [2]  [ 480/4572]  eta: 0:01:32    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [ 500/4572]  eta: 0:01:31    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [ 520/4572]  eta: 0:01:31    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [ 540/4572]  eta: 0:01:31    time: 0.0237  data: 0.0216  max mem: 13749
Epoch: [2]  [ 560/4572]  eta: 0:01:30    time: 0.0230  data: 0.0212  max mem: 13749
Epoch: [2]  [ 580/4572]  eta: 0:01:30    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [2]  [ 600/4572]  eta: 0:01:30    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [ 620/4572]  eta: 0:01:29    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [2]  [ 640/4572]  eta: 0:01:29    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [ 660/4572]  eta: 0:01:28    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [ 680/4572]  eta: 0:01:28    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [ 700/4572]  eta: 0:01:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [ 720/4572]  eta: 0:01:27    time: 0.0226  data: 0.0202  max mem: 13749
Epoch: [2]  [ 740/4572]  eta: 0:01:26    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [ 760/4572]  eta: 0:01:26    time: 0.0251  data: 0.0235  max mem: 13749
Epoch: [2]  [ 780/4572]  eta: 0:01:26    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [2]  [ 800/4572]  eta: 0:01:25    time: 0.0221  data: 0.0205  max mem: 13749
Epoch: [2]  [ 820/4572]  eta: 0:01:25    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [ 840/4572]  eta: 0:01:24    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [ 860/4572]  eta: 0:01:24    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [2]  [ 880/4572]  eta: 0:01:23    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [2]  [ 900/4572]  eta: 0:01:23    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [2]  [ 920/4572]  eta: 0:01:23    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [ 940/4572]  eta: 0:01:22    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [ 960/4572]  eta: 0:01:22    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [ 980/4572]  eta: 0:01:21    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1000/4572]  eta: 0:01:21    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [1020/4572]  eta: 0:01:21    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1040/4572]  eta: 0:01:20    time: 0.0247  data: 0.0228  max mem: 13749
Epoch: [2]  [1060/4572]  eta: 0:01:20    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1080/4572]  eta: 0:01:19    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [2]  [1100/4572]  eta: 0:01:19    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [1120/4572]  eta: 0:01:18    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1140/4572]  eta: 0:01:18    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1160/4572]  eta: 0:01:17    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1180/4572]  eta: 0:01:17    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [1200/4572]  eta: 0:01:17    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [2]  [1220/4572]  eta: 0:01:16    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [1240/4572]  eta: 0:01:16    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [2]  [1260/4572]  eta: 0:01:15    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1280/4572]  eta: 0:01:15    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [1300/4572]  eta: 0:01:14    time: 0.0230  data: 0.0210  max mem: 13749
Epoch: [2]  [1320/4572]  eta: 0:01:14    time: 0.0228  data: 0.0208  max mem: 13749
Epoch: [2]  [1340/4572]  eta: 0:01:13    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1360/4572]  eta: 0:01:13    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [1380/4572]  eta: 0:01:12    time: 0.0219  data: 0.0201  max mem: 13749
Epoch: [2]  [1400/4572]  eta: 0:01:12    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1420/4572]  eta: 0:01:12    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1440/4572]  eta: 0:01:11    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [1460/4572]  eta: 0:01:11    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [1480/4572]  eta: 0:01:10    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1500/4572]  eta: 0:01:10    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [1520/4572]  eta: 0:01:09    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [1540/4572]  eta: 0:01:09    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [1560/4572]  eta: 0:01:08    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1580/4572]  eta: 0:01:08    time: 0.0248  data: 0.0233  max mem: 13749
Epoch: [2]  [1600/4572]  eta: 0:01:08    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [1620/4572]  eta: 0:01:07    time: 0.0244  data: 0.0230  max mem: 13749
Epoch: [2]  [1640/4572]  eta: 0:01:07    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [1660/4572]  eta: 0:01:06    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [1680/4572]  eta: 0:01:06    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [1700/4572]  eta: 0:01:05    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1720/4572]  eta: 0:01:05    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1740/4572]  eta: 0:01:04    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [1760/4572]  eta: 0:01:04    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [1780/4572]  eta: 0:01:03    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [1800/4572]  eta: 0:01:03    time: 0.0218  data: 0.0194  max mem: 13749
Epoch: [2]  [1820/4572]  eta: 0:01:02    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [1840/4572]  eta: 0:01:02    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [1860/4572]  eta: 0:01:01    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [1880/4572]  eta: 0:01:01    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1900/4572]  eta: 0:01:01    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [1920/4572]  eta: 0:01:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [1940/4572]  eta: 0:01:00    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [1960/4572]  eta: 0:00:59    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [1980/4572]  eta: 0:00:59    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [2000/4572]  eta: 0:00:58    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2020/4572]  eta: 0:00:58    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [2040/4572]  eta: 0:00:57    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2060/4572]  eta: 0:00:57    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [2080/4572]  eta: 0:00:56    time: 0.0237  data: 0.0218  max mem: 13749
Epoch: [2]  [2100/4572]  eta: 0:00:56    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [2]  [2120/4572]  eta: 0:00:56    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2140/4572]  eta: 0:00:55    time: 0.0225  data: 0.0209  max mem: 13749
Epoch: [2]  [2160/4572]  eta: 0:00:55    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [2]  [2180/4572]  eta: 0:00:54    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [2200/4572]  eta: 0:00:54    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2220/4572]  eta: 0:00:53    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2240/4572]  eta: 0:00:53    time: 0.0236  data: 0.0211  max mem: 13749
Epoch: [2]  [2260/4572]  eta: 0:00:52    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [2280/4572]  eta: 0:00:52    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2300/4572]  eta: 0:00:51    time: 0.0233  data: 0.0215  max mem: 13749
Epoch: [2]  [2320/4572]  eta: 0:00:51    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [2340/4572]  eta: 0:00:50    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2360/4572]  eta: 0:00:50    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [2]  [2380/4572]  eta: 0:00:50    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [2400/4572]  eta: 0:00:49    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2420/4572]  eta: 0:00:49    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [2440/4572]  eta: 0:00:48    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [2]  [2460/4572]  eta: 0:00:48    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [2]  [2480/4572]  eta: 0:00:47    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2500/4572]  eta: 0:00:47    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2520/4572]  eta: 0:00:46    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [2540/4572]  eta: 0:00:46    time: 0.0222  data: 0.0208  max mem: 13749
Epoch: [2]  [2560/4572]  eta: 0:00:46    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [2]  [2580/4572]  eta: 0:00:45    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2600/4572]  eta: 0:00:45    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2620/4572]  eta: 0:00:44    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2640/4572]  eta: 0:00:44    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [2]  [2660/4572]  eta: 0:00:43    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [2680/4572]  eta: 0:00:43    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [2700/4572]  eta: 0:00:42    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [2720/4572]  eta: 0:00:42    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [2740/4572]  eta: 0:00:41    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [2760/4572]  eta: 0:00:41    time: 0.0227  data: 0.0204  max mem: 13749
Epoch: [2]  [2780/4572]  eta: 0:00:40    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2800/4572]  eta: 0:00:40    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [2820/4572]  eta: 0:00:40    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [2840/4572]  eta: 0:00:39    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [2860/4572]  eta: 0:00:39    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2880/4572]  eta: 0:00:38    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [2900/4572]  eta: 0:00:38    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [2920/4572]  eta: 0:00:37    time: 0.0244  data: 0.0230  max mem: 13749
Epoch: [2]  [2940/4572]  eta: 0:00:37    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [2]  [2960/4572]  eta: 0:00:36    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [2980/4572]  eta: 0:00:36    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3000/4572]  eta: 0:00:35    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3020/4572]  eta: 0:00:35    time: 0.0237  data: 0.0212  max mem: 13749
Epoch: [2]  [3040/4572]  eta: 0:00:35    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [2]  [3060/4572]  eta: 0:00:34    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [3080/4572]  eta: 0:00:34    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [2]  [3100/4572]  eta: 0:00:33    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [3120/4572]  eta: 0:00:33    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [2]  [3140/4572]  eta: 0:00:32    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [2]  [3160/4572]  eta: 0:00:32    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [3180/4572]  eta: 0:00:31    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [3200/4572]  eta: 0:00:31    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [3220/4572]  eta: 0:00:30    time: 0.0244  data: 0.0229  max mem: 13749
Epoch: [2]  [3240/4572]  eta: 0:00:30    time: 0.0235  data: 0.0214  max mem: 13749
Epoch: [2]  [3260/4572]  eta: 0:00:30    time: 0.0245  data: 0.0230  max mem: 13749
Epoch: [2]  [3280/4572]  eta: 0:00:29    time: 0.0274  data: 0.0259  max mem: 13749
Epoch: [2]  [3300/4572]  eta: 0:00:29    time: 0.0237  data: 0.0220  max mem: 13749
Epoch: [2]  [3320/4572]  eta: 0:00:28    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [2]  [3340/4572]  eta: 0:00:28    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [2]  [3360/4572]  eta: 0:00:27    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [2]  [3380/4572]  eta: 0:00:27    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [3400/4572]  eta: 0:00:26    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [3420/4572]  eta: 0:00:26    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [2]  [3440/4572]  eta: 0:00:25    time: 0.0224  data: 0.0210  max mem: 13749
Epoch: [2]  [3460/4572]  eta: 0:00:25    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [3480/4572]  eta: 0:00:25    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [2]  [3500/4572]  eta: 0:00:24    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3520/4572]  eta: 0:00:24    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [2]  [3540/4572]  eta: 0:00:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3560/4572]  eta: 0:00:23    time: 0.0232  data: 0.0216  max mem: 13749
Epoch: [2]  [3580/4572]  eta: 0:00:22    time: 0.0232  data: 0.0218  max mem: 13749
Epoch: [2]  [3600/4572]  eta: 0:00:22    time: 0.0227  data: 0.0211  max mem: 13749
Epoch: [2]  [3620/4572]  eta: 0:00:21    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3640/4572]  eta: 0:00:21    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [2]  [3660/4572]  eta: 0:00:20    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3680/4572]  eta: 0:00:20    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [2]  [3700/4572]  eta: 0:00:19    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3720/4572]  eta: 0:00:19    time: 0.0228  data: 0.0211  max mem: 13749
Epoch: [2]  [3740/4572]  eta: 0:00:19    time: 0.0229  data: 0.0203  max mem: 13749
Epoch: [2]  [3760/4572]  eta: 0:00:18    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [2]  [3780/4572]  eta: 0:00:18    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3800/4572]  eta: 0:00:17    time: 0.0238  data: 0.0222  max mem: 13749
Epoch: [2]  [3820/4572]  eta: 0:00:17    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [2]  [3840/4572]  eta: 0:00:16    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [3860/4572]  eta: 0:00:16    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [2]  [3880/4572]  eta: 0:00:15    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [3900/4572]  eta: 0:00:15    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [2]  [3920/4572]  eta: 0:00:14    time: 0.0225  data: 0.0207  max mem: 13749
Epoch: [2]  [3940/4572]  eta: 0:00:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [2]  [3960/4572]  eta: 0:00:14    time: 0.0218  data: 0.0204  max mem: 13749
Epoch: [2]  [3980/4572]  eta: 0:00:13    time: 0.0218  data: 0.0202  max mem: 13749
Epoch: [2]  [4000/4572]  eta: 0:00:13    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [4020/4572]  eta: 0:00:12    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [2]  [4040/4572]  eta: 0:00:12    time: 0.0231  data: 0.0211  max mem: 13749
Epoch: [2]  [4060/4572]  eta: 0:00:11    time: 0.0240  data: 0.0224  max mem: 13749
Epoch: [2]  [4080/4572]  eta: 0:00:11    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [2]  [4100/4572]  eta: 0:00:10    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4120/4572]  eta: 0:00:10    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4140/4572]  eta: 0:00:09    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4160/4572]  eta: 0:00:09    time: 0.0257  data: 0.0242  max mem: 13749
Epoch: [2]  [4180/4572]  eta: 0:00:08    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [2]  [4200/4572]  eta: 0:00:08    time: 0.0236  data: 0.0210  max mem: 13749
Epoch: [2]  [4220/4572]  eta: 0:00:08    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [2]  [4240/4572]  eta: 0:00:07    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [2]  [4260/4572]  eta: 0:00:07    time: 0.0223  data: 0.0199  max mem: 13749
Epoch: [2]  [4280/4572]  eta: 0:00:06    time: 0.0225  data: 0.0200  max mem: 13749
Epoch: [2]  [4300/4572]  eta: 0:00:06    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [2]  [4320/4572]  eta: 0:00:05    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [2]  [4340/4572]  eta: 0:00:05    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [2]  [4360/4572]  eta: 0:00:04    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [4380/4572]  eta: 0:00:04    time: 0.0239  data: 0.0218  max mem: 13749
Epoch: [2]  [4400/4572]  eta: 0:00:03    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [2]  [4420/4572]  eta: 0:00:03    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [2]  [4440/4572]  eta: 0:00:03    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [2]  [4460/4572]  eta: 0:00:02    time: 0.0250  data: 0.0223  max mem: 13749
Epoch: [2]  [4480/4572]  eta: 0:00:02    time: 0.0218  data: 0.0203  max mem: 13749
Epoch: [2]  [4500/4572]  eta: 0:00:01    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2]  [4520/4572]  eta: 0:00:01    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [2]  [4540/4572]  eta: 0:00:00    time: 0.0222  data: 0.0202  max mem: 13749
Epoch: [2]  [4560/4572]  eta: 0:00:00    time: 0.0240  data: 0.0225  max mem: 13749
Epoch: [2]  [4571/4572]  eta: 0:00:00    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [2] Total time: 0:01:44 (0.0230 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746034271588, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 2, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 2}}
:::MLLOG {"namespace": "", "time_ms": 1746034271588, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 174.2148392864601}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746034271589, "event_type": "INTERVAL_START", "key": "eval_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 3}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2799 (0.2799)  evaluator_time: 0.0032 (0.0032)  time: 0.2842  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2770 (0.2605)  evaluator_time: 0.0035 (0.0033)  time: 0.2649  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2649 s / it)
Averaged stats: model_time: 0.2770 (0.2661)  evaluator_time: 0.0035 (0.0081)
:::MLLOG {"namespace": "", "time_ms": 1746034275591, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 3}}
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished.                              Ignoring...
Epoch: [3]  [   0/4571]  eta: 0:01:36    time: 0.0211  data: 0.0008  max mem: 13749
Epoch: [3]  [  20/4571]  eta: 0:01:57    time: 0.0262  data: 0.0243  max mem: 13749
Epoch: [3]  [  40/4571]  eta: 0:01:52    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [  60/4571]  eta: 0:01:47    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [  80/4571]  eta: 0:01:47    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [ 100/4571]  eta: 0:01:46    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [ 120/4571]  eta: 0:01:45    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3]  [ 140/4571]  eta: 0:01:44    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [ 160/4571]  eta: 0:01:44    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [ 180/4571]  eta: 0:01:43    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [ 200/4571]  eta: 0:01:42    time: 0.0225  data: 0.0209  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746034280415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.32506548759813314, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746034280415, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 3}}
Epoch: [3]  [ 220/4571]  eta: 0:01:41    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [ 240/4571]  eta: 0:01:41    time: 0.0256  data: 0.0241  max mem: 13749
Epoch: [3]  [ 260/4571]  eta: 0:01:41    time: 0.0235  data: 0.0217  max mem: 13749
Epoch: [3]  [ 280/4571]  eta: 0:01:40    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [ 300/4571]  eta: 0:01:39    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [ 320/4571]  eta: 0:01:39    time: 0.0223  data: 0.0209  max mem: 13749
Epoch: [3]  [ 340/4571]  eta: 0:01:38    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [ 360/4571]  eta: 0:01:38    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [ 380/4571]  eta: 0:01:37    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [ 400/4571]  eta: 0:01:37    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [ 420/4571]  eta: 0:01:36    time: 0.0246  data: 0.0231  max mem: 13749
Epoch: [3]  [ 440/4571]  eta: 0:01:36    time: 0.0259  data: 0.0236  max mem: 13749
Epoch: [3]  [ 460/4571]  eta: 0:01:36    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [ 480/4571]  eta: 0:01:35    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [ 500/4571]  eta: 0:01:35    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [ 520/4571]  eta: 0:01:34    time: 0.0238  data: 0.0216  max mem: 13749
Epoch: [3]  [ 540/4571]  eta: 0:01:34    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [ 560/4571]  eta: 0:01:33    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [ 580/4571]  eta: 0:01:33    time: 0.0232  data: 0.0212  max mem: 13749
Epoch: [3]  [ 600/4571]  eta: 0:01:32    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [ 620/4571]  eta: 0:01:32    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [ 640/4571]  eta: 0:01:31    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [ 660/4571]  eta: 0:01:31    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [ 680/4571]  eta: 0:01:31    time: 0.0264  data: 0.0250  max mem: 13749
Epoch: [3]  [ 700/4571]  eta: 0:01:30    time: 0.0233  data: 0.0219  max mem: 13749
Epoch: [3]  [ 720/4571]  eta: 0:01:30    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [ 740/4571]  eta: 0:01:29    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [ 760/4571]  eta: 0:01:29    time: 0.0236  data: 0.0220  max mem: 13749
Epoch: [3]  [ 780/4571]  eta: 0:01:28    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [ 800/4571]  eta: 0:01:28    time: 0.0249  data: 0.0234  max mem: 13749
Epoch: [3]  [ 820/4571]  eta: 0:01:27    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [ 840/4571]  eta: 0:01:27    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [ 860/4571]  eta: 0:01:26    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [ 880/4571]  eta: 0:01:26    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [ 900/4571]  eta: 0:01:25    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [ 920/4571]  eta: 0:01:25    time: 0.0239  data: 0.0223  max mem: 13749
Epoch: [3]  [ 940/4571]  eta: 0:01:24    time: 0.0230  data: 0.0216  max mem: 13749
Epoch: [3]  [ 960/4571]  eta: 0:01:24    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [ 980/4571]  eta: 0:01:23    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1000/4571]  eta: 0:01:23    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1020/4571]  eta: 0:01:22    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1040/4571]  eta: 0:01:22    time: 0.0247  data: 0.0227  max mem: 13749
Epoch: [3]  [1060/4571]  eta: 0:01:21    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [1080/4571]  eta: 0:01:21    time: 0.0270  data: 0.0254  max mem: 13749
Epoch: [3]  [1100/4571]  eta: 0:01:20    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1120/4571]  eta: 0:01:20    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [1140/4571]  eta: 0:01:20    time: 0.0243  data: 0.0220  max mem: 13749
Epoch: [3]  [1160/4571]  eta: 0:01:19    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1180/4571]  eta: 0:01:19    time: 0.0231  data: 0.0214  max mem: 13749
Epoch: [3]  [1200/4571]  eta: 0:01:18    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [1220/4571]  eta: 0:01:18    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1240/4571]  eta: 0:01:17    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1260/4571]  eta: 0:01:17    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1280/4571]  eta: 0:01:16    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [1300/4571]  eta: 0:01:16    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1320/4571]  eta: 0:01:15    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [3]  [1340/4571]  eta: 0:01:15    time: 0.0228  data: 0.0214  max mem: 13749
Epoch: [3]  [1360/4571]  eta: 0:01:14    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1380/4571]  eta: 0:01:14    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1400/4571]  eta: 0:01:13    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [1420/4571]  eta: 0:01:13    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1440/4571]  eta: 0:01:12    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [1460/4571]  eta: 0:01:12    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [1480/4571]  eta: 0:01:11    time: 0.0250  data: 0.0235  max mem: 13749
Epoch: [3]  [1500/4571]  eta: 0:01:11    time: 0.0217  data: 0.0203  max mem: 13749
Epoch: [3]  [1520/4571]  eta: 0:01:10    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [1540/4571]  eta: 0:01:10    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [1560/4571]  eta: 0:01:09    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [1580/4571]  eta: 0:01:09    time: 0.0282  data: 0.0267  max mem: 13749
Epoch: [3]  [1600/4571]  eta: 0:01:08    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1620/4571]  eta: 0:01:08    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [1640/4571]  eta: 0:01:08    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [1660/4571]  eta: 0:01:07    time: 0.0239  data: 0.0217  max mem: 13749
Epoch: [3]  [1680/4571]  eta: 0:01:07    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [1700/4571]  eta: 0:01:06    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [1720/4571]  eta: 0:01:06    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [1740/4571]  eta: 0:01:05    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [1760/4571]  eta: 0:01:05    time: 0.0239  data: 0.0224  max mem: 13749
Epoch: [3]  [1780/4571]  eta: 0:01:04    time: 0.0243  data: 0.0227  max mem: 13749
Epoch: [3]  [1800/4571]  eta: 0:01:04    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [1820/4571]  eta: 0:01:03    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [1840/4571]  eta: 0:01:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [1860/4571]  eta: 0:01:02    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [1880/4571]  eta: 0:01:02    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [1900/4571]  eta: 0:01:01    time: 0.0244  data: 0.0225  max mem: 13749
Epoch: [3]  [1920/4571]  eta: 0:01:01    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [1940/4571]  eta: 0:01:01    time: 0.0233  data: 0.0209  max mem: 13749
Epoch: [3]  [1960/4571]  eta: 0:01:00    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [1980/4571]  eta: 0:01:00    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [2000/4571]  eta: 0:00:59    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [2020/4571]  eta: 0:00:59    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2040/4571]  eta: 0:00:58    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [2060/4571]  eta: 0:00:58    time: 0.0238  data: 0.0223  max mem: 13749
Epoch: [3]  [2080/4571]  eta: 0:00:57    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [2100/4571]  eta: 0:00:57    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2120/4571]  eta: 0:00:56    time: 0.0222  data: 0.0198  max mem: 13749
Epoch: [3]  [2140/4571]  eta: 0:00:56    time: 0.0225  data: 0.0211  max mem: 13749
Epoch: [3]  [2160/4571]  eta: 0:00:55    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2180/4571]  eta: 0:00:55    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2200/4571]  eta: 0:00:54    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [2220/4571]  eta: 0:00:54    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [2240/4571]  eta: 0:00:53    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [3]  [2260/4571]  eta: 0:00:53    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [2280/4571]  eta: 0:00:52    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2300/4571]  eta: 0:00:52    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [2320/4571]  eta: 0:00:52    time: 0.0277  data: 0.0258  max mem: 13749
Epoch: [3]  [2340/4571]  eta: 0:00:51    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [2360/4571]  eta: 0:00:51    time: 0.0232  data: 0.0207  max mem: 13749
Epoch: [3]  [2380/4571]  eta: 0:00:50    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [2400/4571]  eta: 0:00:50    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [2420/4571]  eta: 0:00:49    time: 0.0237  data: 0.0221  max mem: 13749
Epoch: [3]  [2440/4571]  eta: 0:00:49    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [3]  [2460/4571]  eta: 0:00:48    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [2480/4571]  eta: 0:00:48    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [2500/4571]  eta: 0:00:47    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [2520/4571]  eta: 0:00:47    time: 0.0224  data: 0.0208  max mem: 13749
Epoch: [3]  [2540/4571]  eta: 0:00:46    time: 0.0227  data: 0.0207  max mem: 13749
Epoch: [3]  [2560/4571]  eta: 0:00:46    time: 0.0238  data: 0.0224  max mem: 13749
Epoch: [3]  [2580/4571]  eta: 0:00:46    time: 0.0244  data: 0.0227  max mem: 13749
Epoch: [3]  [2600/4571]  eta: 0:00:45    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [2620/4571]  eta: 0:00:45    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [2640/4571]  eta: 0:00:44    time: 0.0235  data: 0.0221  max mem: 13749
Epoch: [3]  [2660/4571]  eta: 0:00:44    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [2680/4571]  eta: 0:00:43    time: 0.0226  data: 0.0207  max mem: 13749
Epoch: [3]  [2700/4571]  eta: 0:00:43    time: 0.0223  data: 0.0207  max mem: 13749
Epoch: [3]  [2720/4571]  eta: 0:00:42    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [3]  [2740/4571]  eta: 0:00:42    time: 0.0226  data: 0.0204  max mem: 13749
Epoch: [3]  [2760/4571]  eta: 0:00:41    time: 0.0238  data: 0.0221  max mem: 13749
Epoch: [3]  [2780/4571]  eta: 0:00:41    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [2800/4571]  eta: 0:00:40    time: 0.0232  data: 0.0217  max mem: 13749
Epoch: [3]  [2820/4571]  eta: 0:00:40    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [2840/4571]  eta: 0:00:40    time: 0.0269  data: 0.0254  max mem: 13749
Epoch: [3]  [2860/4571]  eta: 0:00:39    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [2880/4571]  eta: 0:00:39    time: 0.0225  data: 0.0204  max mem: 13749
Epoch: [3]  [2900/4571]  eta: 0:00:38    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [2920/4571]  eta: 0:00:38    time: 0.0243  data: 0.0228  max mem: 13749
Epoch: [3]  [2940/4571]  eta: 0:00:37    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [2960/4571]  eta: 0:00:37    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [2980/4571]  eta: 0:00:36    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3000/4571]  eta: 0:00:36    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [3]  [3020/4571]  eta: 0:00:35    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3040/4571]  eta: 0:00:35    time: 0.0264  data: 0.0211  max mem: 13749
Epoch: [3]  [3060/4571]  eta: 0:00:34    time: 0.0227  data: 0.0213  max mem: 13749
Epoch: [3]  [3080/4571]  eta: 0:00:34    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [3100/4571]  eta: 0:00:34    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [3]  [3120/4571]  eta: 0:00:33    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [3140/4571]  eta: 0:00:33    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [3]  [3160/4571]  eta: 0:00:32    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3180/4571]  eta: 0:00:32    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3200/4571]  eta: 0:00:31    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3220/4571]  eta: 0:00:31    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3240/4571]  eta: 0:00:30    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3260/4571]  eta: 0:00:30    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [3]  [3280/4571]  eta: 0:00:29    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3300/4571]  eta: 0:00:29    time: 0.0233  data: 0.0211  max mem: 13749
Epoch: [3]  [3320/4571]  eta: 0:00:28    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [3340/4571]  eta: 0:00:28    time: 0.0231  data: 0.0215  max mem: 13749
Epoch: [3]  [3360/4571]  eta: 0:00:28    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [3]  [3380/4571]  eta: 0:00:27    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3400/4571]  eta: 0:00:27    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3420/4571]  eta: 0:00:26    time: 0.0231  data: 0.0217  max mem: 13749
Epoch: [3]  [3440/4571]  eta: 0:00:26    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [3460/4571]  eta: 0:00:25    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [3480/4571]  eta: 0:00:25    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [3500/4571]  eta: 0:00:24    time: 0.0229  data: 0.0213  max mem: 13749
Epoch: [3]  [3520/4571]  eta: 0:00:24    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [3540/4571]  eta: 0:00:23    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [3560/4571]  eta: 0:00:23    time: 0.0237  data: 0.0223  max mem: 13749
Epoch: [3]  [3580/4571]  eta: 0:00:22    time: 0.0235  data: 0.0210  max mem: 13749
Epoch: [3]  [3600/4571]  eta: 0:00:22    time: 0.0242  data: 0.0227  max mem: 13749
Epoch: [3]  [3620/4571]  eta: 0:00:21    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [3640/4571]  eta: 0:00:21    time: 0.0238  data: 0.0214  max mem: 13749
Epoch: [3]  [3660/4571]  eta: 0:00:21    time: 0.0237  data: 0.0222  max mem: 13749
Epoch: [3]  [3680/4571]  eta: 0:00:20    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [3700/4571]  eta: 0:00:20    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3720/4571]  eta: 0:00:19    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [3740/4571]  eta: 0:00:19    time: 0.0239  data: 0.0222  max mem: 13749
Epoch: [3]  [3760/4571]  eta: 0:00:18    time: 0.0226  data: 0.0211  max mem: 13749
Epoch: [3]  [3780/4571]  eta: 0:00:18    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3800/4571]  eta: 0:00:17    time: 0.0217  data: 0.0202  max mem: 13749
Epoch: [3]  [3820/4571]  eta: 0:00:17    time: 0.0222  data: 0.0206  max mem: 13749
Epoch: [3]  [3840/4571]  eta: 0:00:16    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [3860/4571]  eta: 0:00:16    time: 0.0255  data: 0.0240  max mem: 13749
Epoch: [3]  [3880/4571]  eta: 0:00:15    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [3900/4571]  eta: 0:00:15    time: 0.0231  data: 0.0209  max mem: 13749
Epoch: [3]  [3920/4571]  eta: 0:00:15    time: 0.0226  data: 0.0212  max mem: 13749
Epoch: [3]  [3940/4571]  eta: 0:00:14    time: 0.0235  data: 0.0219  max mem: 13749
Epoch: [3]  [3960/4571]  eta: 0:00:14    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [3980/4571]  eta: 0:00:13    time: 0.0227  data: 0.0212  max mem: 13749
Epoch: [3]  [4000/4571]  eta: 0:00:13    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [4020/4571]  eta: 0:00:12    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [4040/4571]  eta: 0:00:12    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [4060/4571]  eta: 0:00:11    time: 0.0219  data: 0.0204  max mem: 13749
Epoch: [3]  [4080/4571]  eta: 0:00:11    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [4100/4571]  eta: 0:00:10    time: 0.0259  data: 0.0244  max mem: 13749
Epoch: [3]  [4120/4571]  eta: 0:00:10    time: 0.0228  data: 0.0205  max mem: 13749
Epoch: [3]  [4140/4571]  eta: 0:00:09    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [4160/4571]  eta: 0:00:09    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [4180/4571]  eta: 0:00:09    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [4200/4571]  eta: 0:00:08    time: 0.0230  data: 0.0212  max mem: 13749
Epoch: [3]  [4220/4571]  eta: 0:00:08    time: 0.0230  data: 0.0215  max mem: 13749
Epoch: [3]  [4240/4571]  eta: 0:00:07    time: 0.0228  data: 0.0213  max mem: 13749
Epoch: [3]  [4260/4571]  eta: 0:00:07    time: 0.0236  data: 0.0221  max mem: 13749
Epoch: [3]  [4280/4571]  eta: 0:00:06    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4300/4571]  eta: 0:00:06    time: 0.0235  data: 0.0220  max mem: 13749
Epoch: [3]  [4320/4571]  eta: 0:00:05    time: 0.0230  data: 0.0214  max mem: 13749
Epoch: [3]  [4340/4571]  eta: 0:00:05    time: 0.0241  data: 0.0226  max mem: 13749
Epoch: [3]  [4360/4571]  eta: 0:00:04    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4380/4571]  eta: 0:00:04    time: 0.0224  data: 0.0209  max mem: 13749
Epoch: [3]  [4400/4571]  eta: 0:00:03    time: 0.0220  data: 0.0205  max mem: 13749
Epoch: [3]  [4420/4571]  eta: 0:00:03    time: 0.0231  data: 0.0216  max mem: 13749
Epoch: [3]  [4440/4571]  eta: 0:00:03    time: 0.0222  data: 0.0207  max mem: 13749
Epoch: [3]  [4460/4571]  eta: 0:00:02    time: 0.0223  data: 0.0208  max mem: 13749
Epoch: [3]  [4480/4571]  eta: 0:00:02    time: 0.0229  data: 0.0214  max mem: 13749
Epoch: [3]  [4500/4571]  eta: 0:00:01    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [3]  [4520/4571]  eta: 0:00:01    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [4540/4571]  eta: 0:00:00    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [3]  [4560/4571]  eta: 0:00:00    time: 0.0233  data: 0.0218  max mem: 13749
Epoch: [3]  [4570/4571]  eta: 0:00:00    time: 0.0234  data: 0.0218  max mem: 13749
Epoch: [3] Total time: 0:01:45 (0.0231 s / it)
:::MLLOG {"namespace": "", "time_ms": 1746034381162, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 3, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1746034381163, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 173.24509262183125}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746034381167, "event_type": "INTERVAL_START", "key": "eval_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 344, "epoch_num": 4}}
Test:  [ 0/13]  eta: 0:00:03  model_time: 0.2651 (0.2651)  evaluator_time: 0.0031 (0.0031)  time: 0.2693  data: 0.0009  max mem: 13749
Test:  [12/13]  eta: 0:00:00  model_time: 0.2692 (0.2556)  evaluator_time: 0.0034 (0.0033)  time: 0.2599  data: 0.0008  max mem: 13749
Test: Total time: 0:00:03 (0.2600 s / it)
Averaged stats: model_time: 0.2692 (0.2614)  evaluator_time: 0.0034 (0.0041)
:::MLLOG {"namespace": "", "time_ms": 1746034384989, "event_type": "INTERVAL_START", "key": "epoch_start", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 158, "epoch_num": 4}}
Epoch: [4]  [   0/4572]  eta: 0:01:39    time: 0.0218  data: 0.0007  max mem: 13749
Epoch: [4]  [  20/4572]  eta: 0:01:46    time: 0.0234  data: 0.0219  max mem: 13749
Epoch: [4]  [  40/4572]  eta: 0:01:47    time: 0.0242  data: 0.0226  max mem: 13749
Epoch: [4]  [  60/4572]  eta: 0:01:44    time: 0.0220  data: 0.0204  max mem: 13749
Epoch: [4]  [  80/4572]  eta: 0:01:44    time: 0.0233  data: 0.0217  max mem: 13749
Epoch: [4]  [ 100/4572]  eta: 0:01:42    time: 0.0221  data: 0.0206  max mem: 13749
Epoch: [4]  [ 120/4572]  eta: 0:01:41    time: 0.0225  data: 0.0210  max mem: 13749
Epoch: [4]  [ 140/4572]  eta: 0:01:41    time: 0.0228  data: 0.0212  max mem: 13749
Epoch: [4]  [ 160/4572]  eta: 0:01:40    time: 0.0223  data: 0.0206  max mem: 13749
Epoch: [4]  [ 180/4572]  eta: 0:01:39    time: 0.0224  data: 0.0207  max mem: 13749
Epoch: [4]  [ 200/4572]  eta: 0:01:39    time: 0.0219  data: 0.0203  max mem: 13749
:::MLLOG {"namespace": "", "time_ms": 1746034389762, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.34616823806402847, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 437, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746034389762, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 438, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746034390002, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 315, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1746034390002, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": 4, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 330, "epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1746034390002, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 177.4164112802226}, "metadata": {"file": "/workspace/ssd/engine.py", "lineno": 334, "step": 5}}
Run time 0:07:23
:::MLLOG {"namespace": "", "time_ms": 1746034390002, "event_type": "POINT_IN_TIME", "key": "status", "value": "success", "metadata": {"file": "/workspace/ssd/train.py", "lineno": 783}}

GPU-790:2765667:2766131 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 3, retcode 3

GPU-790:2765730:2766130 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 2, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 2, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 12, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 13, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 13, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 25, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 30, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 30, retcode 3

GPU-1006:2729481:2729869 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 9, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 14, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-1006:2729476:2729865 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 14, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 5, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 5, retcode 3
Loading annotations into memory...
Done (t=1.09s)
Creating index...
Done (t=1.28s)
Loading and preparing results...
DONE (t=3.88s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=3.14s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.19631
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.32010
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.20515
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00460
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.04499
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.21718
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.33414
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.48254
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50544
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01920
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.17469
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.55185
Loading and preparing results...
DONE (t=2.68s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.44s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29128
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.43561
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.31396
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00758
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07965
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.32100
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.37864
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.54095
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.56806
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03027
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.23060
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61816
Loading and preparing results...
DONE (t=2.36s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.29s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.32507
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47004
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.34843
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.00697
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08955
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35948
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.39563
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.56429
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.59248
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.03411
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24495
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64217
Loading and preparing results...
DONE (t=2.32s)
Running per image evaluation...
Evaluate annotation type *bbox*
DONE (t=2.25s).
Accumulating evaluation results...
DONE (t=0.00s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34617
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49367
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.37173
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.01319
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.09681
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38299
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.40735
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.57951
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.60739
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04352
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26444
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65800

GPU-1006:2729454:2729863 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2729454:2729863 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2729454:2729863 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 10, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-1006:2729476:2729865 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 10, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 50, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 19, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 51, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 51, retcode 3

GPU-761:88577:88989 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 49, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 49, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 49, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 18, retcode 3

GPU-726:2690222:2690616 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 17, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-726:2690220:2690612 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 23, retcode 3

GPU-726:2690139:2690615 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690139:2690615 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690139:2690615 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690208:2690614 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690208:2690614 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-726:2690220:2690612 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 21, retcode 3

GPU-726:2690208:2690614 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2690139:2690615 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690139:2690615 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2690208:2690614 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690208:2690614 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 22, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-726:2690220:2690612 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 22, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 53, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 53, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 53, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-761:88608:88981 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 53, retcode 3

GPU-761:88574:88979 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88614:88980 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88608:88981 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88614:88980 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88614:88980 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88608:88981 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88574:88979 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-761:88574:88979 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 55, retcode 3

GPU-761:88614:88980 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88614:88980 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88574:88979 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-761:88574:88979 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 54, retcode 3

GPU-761:88517:88982 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88517:88982 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88517:88982 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88608:88981 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88614:88980 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88614:88980 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 52, retcode 3

GPU-761:88574:88979 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-761:88574:88979 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 52, retcode 3
[rank16]:[W430 17:33:11.773782597 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-726:2690211:2690618 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690211:2690618 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690211:2690618 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690139:2690615 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690139:2690615 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690208:2690614 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690208:2690614 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 16, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-726:2690220:2690612 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 16, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765729:2766136 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2765729:2766136 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2765729:2766136 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 4, retcode 3

GPU-903:3407888:3408340 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 41, retcode 3

GPU-1006:2729464:2729864 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2729454:2729863 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729454:2729863 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729476:2729865 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 15, retcode 3

GPU-1006:2729464:2729864 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-1006:2729464:2729864 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 15, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2765729:2766136 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2765729:2766136 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 4, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-790:2765744:2766134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 7, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-790:2765744:2766134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 4, retcode 3

GPU-1006:2729411:2729866 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729454:2729863 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729454:2729863 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729411:2729866 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729411:2729866 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729476:2729865 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 11, retcode 3

GPU-1006:2729464:2729864 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-1006:2729464:2729864 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 11, retcode 3

GPU-790:2765734:2766133 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2765729:2766136 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765729:2766136 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2765734:2766133 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765734:2766133 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 6, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-790:2765744:2766134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 6, retcode 3

GPU-726:2690202:2690619 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690211:2690618 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690211:2690618 [0] proxy.cc:1521 NCCL WARN [Proxy Service 16] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690222:2690616 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690222:2690616 [1] proxy.cc:1521 NCCL WARN [Proxy Service 17] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690223:2690613 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690223:2690613 [2] proxy.cc:1521 NCCL WARN [Proxy Service 18] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690227:2690617 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690227:2690617 [3] proxy.cc:1521 NCCL WARN [Proxy Service 19] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690202:2690619 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690202:2690619 [4] proxy.cc:1521 NCCL WARN [Proxy Service 20] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690139:2690615 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690139:2690615 [5] proxy.cc:1521 NCCL WARN [Proxy Service 21] Failed to execute operation Close from rank 20, retcode 3

GPU-790:2765745:2766129 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-726:2690208:2690614 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690208:2690614 [6] proxy.cc:1521 NCCL WARN [Proxy Service 22] Failed to execute operation Close from rank 20, retcode 3

GPU-726:2690220:2690612 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-726:2690220:2690612 [7] proxy.cc:1521 NCCL WARN [Proxy Service 23] Failed to execute operation Close from rank 20, retcode 3

GPU-790:2765745:2766129 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765745:2766129 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765729:2766136 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765729:2766136 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765734:2766133 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765734:2766133 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 1, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-790:2765744:2766134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 1, retcode 3
[rank32]:[W430 17:33:11.278389169 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-753:3584519:3584953 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 34, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584573:3584958 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 34, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 32, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 34, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 35, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3584568:3584954 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-753:3584566:3584959 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 33, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584568:3584954 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584546:3584957 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584511:3584960 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584511:3584960 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584511:3584960 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584568:3584954 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584566:3584959 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584568:3584954 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584546:3584957 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-753:3584546:3584957 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 37, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584511:3584960 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584511:3584960 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584511:3584960 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584511:3584960 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584566:3584959 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584566:3584959 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584546:3584957 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-753:3584546:3584957 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 39, retcode 3

GPU-753:3584546:3584957 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-753:3584546:3584957 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 36, retcode 3

GPU-753:3584559:3584956 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-753:3584519:3584953 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584519:3584953 [0] proxy.cc:1521 NCCL WARN [Proxy Service 32] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584568:3584954 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584568:3584954 [1] proxy.cc:1521 NCCL WARN [Proxy Service 33] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584572:3584955 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584572:3584955 [2] proxy.cc:1521 NCCL WARN [Proxy Service 34] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584573:3584958 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584573:3584958 [3] proxy.cc:1521 NCCL WARN [Proxy Service 35] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584511:3584960 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584511:3584960 [4] proxy.cc:1521 NCCL WARN [Proxy Service 36] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584566:3584959 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584566:3584959 [5] proxy.cc:1521 NCCL WARN [Proxy Service 37] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584559:3584956 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584559:3584956 [6] proxy.cc:1521 NCCL WARN [Proxy Service 38] Failed to execute operation Close from rank 38, retcode 3

GPU-753:3584546:3584957 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-753:3584546:3584957 [7] proxy.cc:1521 NCCL WARN [Proxy Service 39] Failed to execute operation Close from rank 38, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 45, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 45, retcode 3
[rank48]:[W430 17:33:11.626961867 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-761:88607:88993 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-761:88607:88993 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88607:88993 [0] proxy.cc:1521 NCCL WARN [Proxy Service 48] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88577:88989 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88577:88989 [1] proxy.cc:1521 NCCL WARN [Proxy Service 49] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88591:88987 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88591:88987 [2] proxy.cc:1521 NCCL WARN [Proxy Service 50] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88622:88986 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88622:88986 [3] proxy.cc:1521 NCCL WARN [Proxy Service 51] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88517:88982 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88517:88982 [4] proxy.cc:1521 NCCL WARN [Proxy Service 52] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88608:88981 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88608:88981 [5] proxy.cc:1521 NCCL WARN [Proxy Service 53] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88614:88980 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88614:88980 [6] proxy.cc:1521 NCCL WARN [Proxy Service 54] Failed to execute operation Close from rank 48, retcode 3

GPU-761:88574:88979 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-761:88574:88979 [7] proxy.cc:1521 NCCL WARN [Proxy Service 55] Failed to execute operation Close from rank 48, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 43, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 43, retcode 3
[rank8]:[W430 17:33:11.738842863 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-1006:2729483:2729867 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-1006:2729483:2729867 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729483:2729867 [0] proxy.cc:1521 NCCL WARN [Proxy Service 8] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729481:2729869 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729481:2729869 [1] proxy.cc:1521 NCCL WARN [Proxy Service 9] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729454:2729863 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729454:2729863 [2] proxy.cc:1521 NCCL WARN [Proxy Service 10] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729411:2729866 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729411:2729866 [3] proxy.cc:1521 NCCL WARN [Proxy Service 11] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729435:2729868 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729435:2729868 [4] proxy.cc:1521 NCCL WARN [Proxy Service 12] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729480:2729870 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729480:2729870 [5] proxy.cc:1521 NCCL WARN [Proxy Service 13] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729476:2729865 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729476:2729865 [6] proxy.cc:1521 NCCL WARN [Proxy Service 14] Failed to execute operation Close from rank 8, retcode 3

GPU-1006:2729464:2729864 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-1006:2729464:2729864 [7] proxy.cc:1521 NCCL WARN [Proxy Service 15] Failed to execute operation Close from rank 8, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3407949:3408343 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 42, retcode 3

GPU-903:3407950:3408341 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3407949:3408343 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3407950:3408341 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3407950:3408341 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 44, retcode 3

GPU-903:3407944:3408337 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407949:3408343 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407950:3408341 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407950:3408341 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407944:3408337 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-903:3407944:3408337 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 47, retcode 3

GPU-903:3407963:3408338 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407949:3408343 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407950:3408341 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407950:3408341 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407963:3408338 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407963:3408338 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 46, retcode 3

GPU-903:3407944:3408337 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-903:3407944:3408337 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 46, retcode 3
[rank24]:[W430 17:33:11.919660854 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-47:4089343:4089696 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 24, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 24, retcode 3
[rank40]:[W430 17:33:11.258442586 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-903:3407966:3408344 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-903:3407966:3408344 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407966:3408344 [0] proxy.cc:1521 NCCL WARN [Proxy Service 40] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407888:3408340 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407888:3408340 [1] proxy.cc:1521 NCCL WARN [Proxy Service 41] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407949:3408343 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407949:3408343 [2] proxy.cc:1521 NCCL WARN [Proxy Service 42] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407957:3408342 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407957:3408342 [3] proxy.cc:1521 NCCL WARN [Proxy Service 43] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407950:3408341 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407950:3408341 [4] proxy.cc:1521 NCCL WARN [Proxy Service 44] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407962:3408339 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407962:3408339 [5] proxy.cc:1521 NCCL WARN [Proxy Service 45] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407963:3408338 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407963:3408338 [6] proxy.cc:1521 NCCL WARN [Proxy Service 46] Failed to execute operation Close from rank 40, retcode 3

GPU-903:3407944:3408337 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-903:3407944:3408337 [7] proxy.cc:1521 NCCL WARN [Proxy Service 47] Failed to execute operation Close from rank 40, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 26, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 26, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4089318:4089698 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 26, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 26, retcode 3

GPU-47:4089272:4089699 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4089318:4089698 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4089272:4089699 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4089272:4089699 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 27, retcode 3

GPU-47:4089327:4089702 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089318:4089698 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089272:4089699 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089272:4089699 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089327:4089702 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089327:4089702 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 29, retcode 3

GPU-47:4089271:4089703 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089318:4089698 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089272:4089699 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089272:4089699 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089327:4089702 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089327:4089702 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089271:4089703 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-47:4089271:4089703 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 31, retcode 3

GPU-47:4089322:4089700 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-47:4089343:4089696 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089343:4089696 [0] proxy.cc:1521 NCCL WARN [Proxy Service 24] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089294:4089697 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089294:4089697 [1] proxy.cc:1521 NCCL WARN [Proxy Service 25] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089318:4089698 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089318:4089698 [2] proxy.cc:1521 NCCL WARN [Proxy Service 26] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089272:4089699 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089272:4089699 [3] proxy.cc:1521 NCCL WARN [Proxy Service 27] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089322:4089700 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089322:4089700 [4] proxy.cc:1521 NCCL WARN [Proxy Service 28] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089327:4089702 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089327:4089702 [5] proxy.cc:1521 NCCL WARN [Proxy Service 29] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089321:4089701 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089321:4089701 [6] proxy.cc:1521 NCCL WARN [Proxy Service 30] Failed to execute operation Close from rank 28, retcode 3

GPU-47:4089271:4089703 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-47:4089271:4089703 [7] proxy.cc:1521 NCCL WARN [Proxy Service 31] Failed to execute operation Close from rank 28, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037153:4037538 [2] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 58, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 3, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 59, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 1, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 57, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 2, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 58, retcode 3
[rank56]:[W430 17:33:11.873400585 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-682:4037141:4037544 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037141:4037544 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4037141:4037544 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 56, retcode 3

GPU-682:4037141:4037544 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4037141:4037544 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4037147:4037540 [6] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4037147:4037540 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 6, res=3, closed=0

GPU-682:4037147:4037540 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 62, retcode 3

GPU-682:4037131:4037541 [5] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037141:4037544 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037141:4037544 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037131:4037541 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037131:4037541 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037147:4037540 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 5, res=3, closed=0

GPU-682:4037147:4037540 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 61, retcode 3

GPU-682:4037151:4037543 [4] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037141:4037544 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037141:4037544 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037151:4037543 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037151:4037543 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037131:4037541 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037131:4037541 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037147:4037540 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 4, res=3, closed=0

GPU-682:4037147:4037540 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 60, retcode 3

GPU-682:4037125:4037542 [7] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-682:4037141:4037544 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037141:4037544 [0] proxy.cc:1521 NCCL WARN [Proxy Service 56] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037066:4037537 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037066:4037537 [1] proxy.cc:1521 NCCL WARN [Proxy Service 57] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037153:4037538 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037153:4037538 [2] proxy.cc:1521 NCCL WARN [Proxy Service 58] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037126:4037539 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037126:4037539 [3] proxy.cc:1521 NCCL WARN [Proxy Service 59] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037151:4037543 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037151:4037543 [4] proxy.cc:1521 NCCL WARN [Proxy Service 60] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037131:4037541 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037131:4037541 [5] proxy.cc:1521 NCCL WARN [Proxy Service 61] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037147:4037540 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037147:4037540 [6] proxy.cc:1521 NCCL WARN [Proxy Service 62] Failed to execute operation Close from rank 63, retcode 3

GPU-682:4037125:4037542 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 7, res=3, closed=0

GPU-682:4037125:4037542 [7] proxy.cc:1521 NCCL WARN [Proxy Service 63] Failed to execute operation Close from rank 63, retcode 3
[rank0]:[W430 17:33:12.689548576 ProcessGroupNCCL.cpp:1218] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())

GPU-790:2765758:2766132 [0] proxy.cc:1458 NCCL WARN [Service thread] Accept failed Resource temporarily unavailable

GPU-790:2765758:2766132 [0] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765758:2766132 [0] proxy.cc:1521 NCCL WARN [Proxy Service 0] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765745:2766129 [1] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765745:2766129 [1] proxy.cc:1521 NCCL WARN [Proxy Service 1] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765730:2766130 [2] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765730:2766130 [2] proxy.cc:1521 NCCL WARN [Proxy Service 2] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765667:2766131 [3] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765667:2766131 [3] proxy.cc:1521 NCCL WARN [Proxy Service 3] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765729:2766136 [4] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765729:2766136 [4] proxy.cc:1521 NCCL WARN [Proxy Service 4] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765765:2766135 [5] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765765:2766135 [5] proxy.cc:1521 NCCL WARN [Proxy Service 5] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765734:2766133 [6] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765734:2766133 [6] proxy.cc:1521 NCCL WARN [Proxy Service 6] Failed to execute operation Close from rank 0, retcode 3

GPU-790:2765744:2766134 [7] proxy.cc:1497 NCCL WARN [Service thread] Could not receive type from localRank 0, res=3, closed=0

GPU-790:2765744:2766134 [7] proxy.cc:1521 NCCL WARN [Proxy Service 7] Failed to execute operation Close from rank 0, retcode 3
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:15 PM
RESULT,SINGLE_STAGE_DETECTOR,,537,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 05:24:17 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:16 PM
RESULT,SINGLE_STAGE_DETECTOR,,538,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 05:24:18 PM
ENDING TIMING RUN AT 2025-04-30 05:33:17 PM
RESULT,SINGLE_STAGE_DETECTOR,,539,nvidia,2025-04-30 05:24:18 PM
++ date +%s
+ echo 'RUNANDTIME_STOP 1746034397'
RUNANDTIME_STOP 1746034397
+ set -e
